---
title: "Simulated Probabilistic Distributions"
author: "Win Cowger"
date: "06/3/2021"
output:   
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
    includes:
     # after_body: footer.html
  word_document:
    toc: yes
---


#Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=8, fig.path='Figs2/',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

```{r library}
# Bimodal universal shape distribution for environmental microplastic from Kooi and Koelmans (2019)
library(truncnorm)
library(tidyverse)
library(MonteCarlo)# Monte Carlo Simulation 
library(gridExtra)
library(msm) ## rtnorm - get upper and lower limit of shape distribution
library(GeneralizedHyperbolic) ## normal-inverse Gaussian
library(skimr)
library(drc) #dose-response curves
library(readr)
library(readxl)
library(DALEX)
library(tigerstats)
library(caret)
library(knitr)
library(modelplotr)
library(rsample)
library(interpret) #explainable boosting machine
library(ssdtools)
library(ggrepel)
library(scales)
library(ggdark)
library(ggsci)
```

```{r Theme, include=FALSE}
#Theme type
     theme.type<- theme_bw(base_size = 14) +
                  #     dark_theme_bw(base_size = 15) +
                    theme(plot.title = element_text(hjust = 0.5),
                    plot.subtitle = element_text(hjust = 0.5))

     #color selection
     fill.type <-    #scale_fill_viridis(discrete = TRUE)#,
                         #scale_fill_brewer(palette = "Paired"),
                         # scale_fill_tron()#,
                         # scale_fill_locuszoom(),
                         # scale_fill_d3(),
                          scale_fill_npg()#,
                         # scale_fill_jama())
     #color selection
     color.type <- #scale_color_viridis(discrete = TRUE)#,
                         # scale_color_brewer(palette = "Paired"),
                          #scale_color_tron()#,
                         # scale_color_locuszoom(),
                         # scale_color_d3(),
                          scale_color_npg()#,
                         # scale_color_jama())

```

```{r data import}
require(readr)
#load aoc_z into dataframe. This file is generated from RDA_Maker.R
#source("Tox Data/RDA_Maker.R")
aoc_z <- readRDS(file = "Tox Data/aoc_z.Rda")
## Data filtering
```

To ensure quality data feeds the model, we are filtering for technical red criteria.
```{r}
## First filter data with global filters
aoc_intermediate <- aoc_z %>% 
  filter(size.length.um.used.for.conversions > 1) %>%  #alignments only valid above 1 um
  filter(tier_zero_tech_f == "Red Criteria Passed",
         #tier_zero_risk_f == "Red Criteria Passed",
         polymer != "Not Reported",
         !environment %in% c("Terrestrial", "Not Reported"),
         #org_f != "Bacterium",
         org_f != "Plant",
         #effect.metric != "HONEC",
         risk.13 != 0 #Drop studies that received a score of 0 for endpoints criteria (this also drops studies that have not yet been scored) - KEEP THIS AFTER THE RED CRITERIA FILTERS  
         ) %>% 
  #Remove 26C temperature treatment data from Jaimukar et al. 2018
  filter(!(article == 42 & media.temp == 26)) %>% 
  mutate(max.size.ingest.um = 1000 * max.size.ingest.mm) %>%   #makes it less confusing below
  droplevels()  #eliminate polymer aand shape data that's not needed
```


The idea here is we want to be able to just change the dataset and model here and then the entire code base will react to the update. The challenge is that making the right synthetic and uniform datasets will differ depending on the column types. Is it safe to assume that there will be no numeric variables in the model besides the concentrations which will be present in the development of the synthetic and uniform datasets?  

# Shape and Polymer Composition in Database vs. Environment
## Polmyer
```{r}
require(reshape2)
Environment_poly <- tibble(
        EVA = 0.06,
        LTX = 0,
        PA = 0.12,
        PC = 0,
        PE = 0.25,
        PET = 0.165,
        PLA = 0,
        PMMA = 0,
        PP = 0.145,
        PS = 0.085,
        PUR = 0,
        PVC = 0.02
) %>% 
  melt() %>% 
  rename("polymer" = "variable",
         "freq" = "value") %>% 
  mutate(type = "environment")

# plot
aoc_intermediate %>% 
  filter(polymer != "Not Reported") %>% 
  group_by(polymer) %>% 
  summarize(count = n()) %>% 
  mutate(freq = count / sum(count)) %>% 
  mutate(polymer = fct_reorder(polymer, freq),
         type = "tox") %>% 
  dplyr::select(-count) %>% 
  rbind(Environment_poly) %>% 
  ggplot(aes(x = freq, y = polymer, fill = type)) +
  geom_col(position = "dodge") +
  labs(title = "Microplastics Polymers in Environment vs. Toxicity Database") +
  scale_x_continuous(labels = scales::percent) +
  xlab("Relative Frequency") +
  theme.type +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank(),
        legend.position = "top") +
  scale_fill_d3(labels = c("Environment", "Toxicity Database"))
```

## Shape
```{r}
Environment_shape <- tibble(
        fiber = 0.485,
        fragment = 0.31,
        sphere = 0.065,
        film = 0.055,
        foam = 0.035
) %>% 
  melt() %>% 
  rename("shape" = "variable",
         "freq" = "value") %>% 
  mutate(type = "environment")

# plot
aoc_intermediate %>% 
  filter(shape != "Not Reported") %>% 
  group_by(shape) %>% 
  summarize(count = n()) %>% 
  mutate(freq = count / sum(count)) %>% 
  mutate(shape = fct_reorder(shape, freq),
         type = "tox") %>% 
  dplyr::select(-count) %>% 
  rbind(Environment_shape) %>% 
  ggplot(aes(x = freq, y = shape, fill = type)) +
  geom_col(position = "dodge") +
  labs(title = "Microplastics Shape Abundances in Environment vs. Toxicity Database") +
  xlab("Relative Frequency") +
  scale_x_continuous(labels = scales::percent) +
  theme.type +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank(),
        legend.position = "top") +
  scale_fill_d3(labels = c("Environment", "Toxicity Database"))

```


# Model Build

### Alignment

#### Parameters
```{r}
## parametrization ##
# Define params for correction #
alpha = 2.07 #table s4 for marine surface water. length
# define parameters for power law coefficients
a.sa = 1.5 #marine surface area power law
a.v = 1.48 #a_V for marine surface water volume
a.m = 1.32 # upper limit fora_m for mass for marine surface water in table S4 
a.ssa = 1.98 # A_SSA for marine surface water

#define additional parameters for calculations based on averages in the environment
R.ave = 0.77 #average width to length ratio for microplastics in marine enviornment
p.ave = 1.10 #average density in marine surface water

#join alpha values for each data point
aoc_intermediate_alphas <- aoc_intermediate %>% 
  mutate(alpha = alpha) %>% 
  mutate(a.sa = a.sa) %>% 
   mutate(a.v =  a.v) %>% 
   mutate(a.m =  a.m) %>% 
   mutate(a.ssa = a.ssa) %>% 
   mutate(R.ave = R.ave) %>% 
   mutate(p.ave = p.ave)
```

#### Functions
```{r}
###function to derive correction factor (CF) from Koelmans et al (equation 2)
CFfnx = function(a, #default alpha from Koelmans et al (2020)
                 x2D, #set detault values to convert ranges to (1-5,000 um) #5mm is upper defuault 
                 x1D, #1 um is lower default size
                 x2M, x1M){
  CF = (x2D^(1-a)-x1D^(1-a))/(x2M^(1-a)-x1M^(1-a)) 
  return(CF)}

#### equations for mu_x_poly (note that there are three depending on certain alphas for limits of equation)
#generalizable if a.x =2 or not
mux.polyfnx_generalizable = Vectorize(function(a.x, x_UL, x_LL){
  if(a.x == 1){ # in case a.x = 1
    mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL))
    return(mux.poly)}
  if(a.x == 2){ # in case a.x = 2
     mux.poly = (log10(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
     return(mux.poly)}
  else{ #in case alpha is not 2 or 1
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}
  },
  vectorize.args = "a.x") # if Vectorize isn't here, the if else won't work
## ^^ Note that the above generalizable function doesn't play well with mutate(case_when), likely due to some bug with dplyr. I don't have a solution to this, so a special equation will need to be used when those values are used...

#in case alpha is not 1 or 2
mux.polyfnx = function(a.x, x_UL, x_LL){
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}

##### If alpha does equal 2 #####
mux.polyfnx2 = function(a.x, x_UL,x_LL){
  mux.poly = (log(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
  return(mux.poly)}

##### If alpha equals 1 #####
mux.polyfnx1 = function(a.x, x_UL, x_LL){
     mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL)) #natural log
    return(mux.poly)}

### Calculating max ingestible parameters ###
## function to calcualte min and max ingestible surface area ##
SAfnx = function(a, # a = 0.5 * length
                 b, # b = 0.5 * width
                 c # c = 0.5 * height (note that hieght is 0.67 * width)
){
  SA = 4*pi*(((a*b)^1.6 + (a*c)^1.6 + (b*c)^1.6) / 3)^(1/1.6)
  return(SA)}

## max ingestible volume ##

volumefnx = function(R, L){
  volume = 0.111667 * pi * R^2 * L^3 #assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
  return(volume)}

volumefnx_poly = function(width, length){
  height = width #0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  return(volume)}

#max ingestible mass (only used for mu_mono calculations)
massfnx = function(R, L, p){
  mass = p * #density (g/cm^3)
    0.111667 * pi * R^2 * L^3 * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

massfnx_poly = function(width, length, p){
  height = width #0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  mass = p * #density (g/cm^3)
    volume * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

#max ingestible specific surface area
SSAfnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA = sa/m
    return(SSA)}

#max ingestible specific surface area
SSA.inversefnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA.inverse = m / sa
    return(SSA.inverse)}
```

#### Calculate

Here we will calculate two aligned exposure concentrations: surface area (1 - 83 um), and volume (1 - 5,000 um). For both, the upper aligned value is the smaller of either the nominal size listed or the mouth size of the species.
##### Tissue Translocation 
```{r}
###define sizes for alignment##
x1M_set <- 1 #um lower size for all alignments
x1D_set <- 1 #um lower size for all alignments
x2D_set <- 5000 #um
upper.tissue.trans.size.um <- 83 #10 #um #set size for x2M

# calculate ERM for each species
aoc_final <- aoc_intermediate_alphas  %>% 
   #### TISSUE TRANSLOCATION ####
# define upper size length for Translocation 
#set to 83um for upper limit or max size ingest, whichever is smaller
mutate(x2M_trans = case_when(is.na(max.size.ingest.um) ~ upper.tissue.trans.size.um, 
                             max.size.ingest.um  < upper.tissue.trans.size.um ~  max.size.ingest.um,
                             max.size.ingest.um  > upper.tissue.trans.size.um ~ upper.tissue.trans.size.um)) %>% 
  
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_trans = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_trans = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_trans, #upper ingestible size limit (width of particle)
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.p.mono)/mu.p.poly_trans) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_trans = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_trans, #upper translocatable
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_trans = EC_poly_p.particles.mL_trans * CF_bio_trans) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  #### Surface area ERM ####
##--- environmental calculations ---###
  #calculate lower translocatable surface area
  mutate(x_LL_sa_trans = SAfnx(a = 0.5 * x1D_set, #length
                               b = 0.5 * x1D_set, #0.5 * R.ave * x1D_set, #width
                               c = 0.5 * x1D_set  #0.5 * R.ave * 0.67 * x1D_set #height
                               )) %>%  
  #calculate upper translocatable surface area
  mutate(x_UL_sa_trans = SAfnx(a = 0.5 * x2M_trans, 
                               b = 0.5 * x2M_trans, #width #0.5 * R.ave * x2M, 
                               c = 0.5 * x2M_trans #heigth #0.5 * R.ave * 0.67 * x2M
                               )) %>%  
  #calculate mu_x_poly (env) for surface area
  mutate(mu.sa.poly_trans = mux.polyfnx(a.sa, x_UL_sa_trans, x_LL_sa_trans)) %>% 
  
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.sa.mono = case_when(
    polydispersity == "monodisperse" ~ particle.surface.area.um2, # use reported surface area in monodisperse
    polydispersity == "polydisperse" ~  mux.polyfnx(a.x = a.sa, 
                                  x_LL = particle.surface.area.um2.min,
                                  x_UL = particle.surface.area.um2.max))) %>% 
  
   #calculate polydisperse effect concentration for surface area (particles/mL)
  mutate(EC_poly_sa.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.sa.mono)/mu.sa.poly_trans) %>%  
  #calculate environmentally realistic effect threshold
  mutate(EC_env_sa.particles.mL_trans = EC_poly_sa.particles.mL_trans * CF_bio_trans) %>% 
  
  ##### FOOD DILUTION ####
  # define upper size length for ingestion 
  mutate(x2M_ingest = case_when(is.na(max.size.ingest.um) ~ x2D_set, 
                         max.size.ingest.um < x2D_set ~ max.size.ingest.um,
                         max.size.ingest.um > x2D_set ~ x2D_set
                         )) %>%  #set to 5,000 as upper limit or max size ingest, whichever is smaller
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_ingest = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_ingest = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_ingest, #upper ingestible size limit
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.p.mono)/mu.p.poly_ingest) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_ingest = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_ingest, #upper ingestible length
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default upper size range
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_ingest = EC_poly_p.particles.mL_ingest * CF_bio_ingest) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  
  #### volume ERM ####
##--- environmental calculations ---###
  #calculate lower ingestible volume 
  mutate(x_LL_v_ingest = volumefnx_poly(length = x1D_set,
                                 width = x1D_set)) %>% 
  #calculate maximum ingestible volume 
  mutate(x_UL_v_ingest = volumefnx_poly(length = x2M_ingest, # length-limited
                                 #x2D_set, #upper definiton (accouunts for fibers) CONSERVATIVE
                                 width = x2M_ingest)) %>% #ingestion-limited
  # calculate mu.v.poly
  mutate(mu.v.poly_ingest = mux.polyfnx(a.v, x_UL_v_ingest, x_LL_v_ingest)) %>% 
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.v.mono = case_when(
    polydispersity == "monodisperse" ~ particle.volume.um3, # use reported volume in monodisperse
    polydispersity == "polydisperse" ~ mux.polyfnx(a.x = a.v, 
                                                   x_LL = particle.volume.um3.min,
                                                   x_UL = particle.volume.um3.max))) %>% 
  
  #calculate polydisperse effect concentration for volume (particles/mL)
  mutate(EC_poly_v.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.v.mono)/mu.v.poly_ingest) %>%  
    #calculate environmentally realistic effect threshold
  mutate(EC_env_v.particles.mL_ingest = EC_poly_v.particles.mL_ingest * CF_bio_ingest) %>% 
  
   ###### CLEANUP #####
  mutate(particles.mL.ox.stress = EC_env_sa.particles.mL_trans,
         particles.mL.food.dilution = EC_env_v.particles.mL_ingest)
```

####Test to see if same thresholds attained in main risk calculation
##### SSD Functions
```{r}
#### define function for SSD generation for tier 1 ####
SSD_function_t1 <- function(filtered.data, hcxlcl){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.25))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, ic = "aicc", nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc5lcl <- c(preds$lcl[hcxlcl]) #CI95
#values to extract
print(hc5lcl)
}

# Leave-one-out by study function
sensitivity_t1 <- Vectorize(function(x, y) {
  train <- filtered.data[!filtered.data$doi %in% x,]
   SSD_function_t1(train, hcxlcl = y)
})

#### define function for SSD generation for tier 2 ####
SSD_function_t2 <- function(filtered.data, hcx){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.25))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, ic = "aicc", nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc <- c(preds$est[hcx]) #HC5
#values to extract
#print(hc5)
print(hc)
}

#### define function for SSD generation for tiers 3 and 4 ####
SSD_function_t3_4 <- function(filtered.data, hcx){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  #filter specific things for tiers 3 and 4
   filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population")) %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.50))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, ic = "aicc", nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc <- c(preds$est[hcx]) #HC5
#values to extract
#print(hc5)
print(hc)
}
```
##### Base Thresholds
```{r}
####---- TISSUE TRANSLOCATION ------#####
filtered.data.small.default_t1.2 <- aoc_final %>% 
          mutate(dose_new = particles.mL.ox.stress / (af.time * af.noec)) %>%  
         drop_na(dose_new) %>% 
         mutate(dose_new = dose_new * 1000) %>% 
  filter(between(size.length.um.used.for.conversions, 1, upper.tissue.trans.size.um))

filtered.data.small.default_t3.4 <- filtered.data.small.default_t1.2 %>% 
 filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population"))

# get thresholds
small.default.t1 <- SSD_function_t1(filtered.data = filtered.data.small.default_t1.2, hcxlcl = 5)
small.default.t2 <- SSD_function_t2(filtered.data = filtered.data.small.default_t1.2, hcx = 5)
small.default.t3 <- SSD_function_t3_4(filtered.data = filtered.data.small.default_t3.4, hcx = 5)
small.default.t4 <- SSD_function_t3_4(filtered.data = filtered.data.small.default_t3.4, hcx = 10)

####---- Food Dilution ------#####
filtered.data.large.default_t1.2 <- aoc_final %>% 
   # remove algae, as food dilution MOE doesn't make sense for algae
  filter(Group != "Algae") %>% 
         mutate(dose_new = particles.mL.food.dilution / (af.time * af.noec)) %>%  
         drop_na(dose_new) %>% 
         mutate(dose_new = dose_new * 1000) %>% 
  filter(between(size.length.um.used.for.conversions, x1D_set, x2D_set))

filtered.data.large.default_t3.4 <- filtered.data.large.default_t1.2 %>% 
 filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population"))

# get thresholds
large.default.t1 <- SSD_function_t1(filtered.data = filtered.data.large.default_t1.2, hcxlcl = 5)
large.default.t2 <- SSD_function_t2(filtered.data = filtered.data.large.default_t1.2, hcx = 5)
large.default.t3 <- SSD_function_t3_4(filtered.data = filtered.data.large.default_t3.4, hcx = 5)
large.default.t4 <- SSD_function_t3_4(filtered.data = filtered.data.large.default_t3.4, hcx = 10)

base_thresholds <- tibble(
  "Tier" = c('Tier1', 'Tier2', 'Tier3', 'Tier4'),
  "Tissue Translocation (Default)" = c(small.default.t1, small.default.t2, small.default.t3, small.default.t4),
  "Food Dilution (Default)" = c(large.default.t1, large.default.t2, large.default.t3, large.default.t4))

base_thresholds
```



### Oxidative Stress
```{r GLM build 1}
require(reshape2)
# data preparation
df_oxidative.stress <- aoc_final %>% 
 #filter data select predictor variables#
  dplyr::select(c(
    ### DOSE METRICS ####
                  particles.mL.ox.stress,
                 # particles.mL.food.dilution,
                  #dose.mg.L.master, 
                  #dose.surface.area.um2.mL.master, #fibers are assumed to be cylinders, fragments are assumed to be spheres
                  #dose.particles.mL.master, 
    ### Organism characteristics ###
                  organism.group, 
                  life.stage, #use adults for prediction
                  species_f, 
                  max.size.ingest.mm,
    ### Exposure Conditions ####              
                  bio.org, #use tissue and above for lower tiers, organism and above for higher tiers
                  exposure.route, #train on all, but only use "aquatic" for build
                  environment, #train on all, buit only use "marine" for SSD Build
                  acute.chronic_f, #use 'chronic' for SSD build
                  exposure.duration.d, 
    ### Particle characteristics ####
                  polymer, 
                  shape,
                  #density.g.cm3,
                  #size.length.um.used.for.conversions, #we can't use size because we're using mixtures of particles! Have to specify translocatable or not
                  translocatable,
    ### Effect data ####
                 # effect, 
                  effect.score, #relative numerical strength of effect
                  effect.metric, #train on all, but only specify "NOEC" for SSD build
                  lvl1_f, #keep it generic for easy SSD build (use fitness)
                  lvl2_f,
                  #lvl3_f
                  )) %>% 
   rowid_to_column(var = "rowid") %>% 
  mutate(value = 1) %>% 
  mutate(particles.mL.ox.stress = log10(particles.mL.ox.stress)) %>% 
  ###### create new column for polymer percentage #####
  dcast(... ~ polymer, value.var = c("value")) %>% 
  # provide 0 for all 'na's'
  mutate(across(.cols = last_col() + (-11:0),
                .fns = ~replace(., is.na(.), 0),
                .names = "{.col}_frac")) %>% 
###### create new column for shape percentage #####
mutate(value = 1) %>% 
  dcast(... ~ shape, value.var = c("value")) %>% 
  # not all rows have unique identifiers (basically dupes), so need to eliminate values > 1
  mutate(across(.cols = last_col() + (-2:0),
                .fns = ~replace(., is.na(.), 0),
                .names = "{.col}_frac")) %>% 
  mutate(effect.metric = (case_when(
    effect.metric == "NOEC" ~ "NOEC",
    effect.metric == "NONEC" ~ "NOEC",
    effect.metric == "HONEC" ~ "NOEC",
    effect.metric == "LOEC" ~ "LOEC",
    effect.metric == "LC50" ~ "LC50",
    effect.metric == "EC50" ~"EC50",
    effect.metric == "EC10" ~ "EC10"
  ))) %>% 
 mutate(effect.metric = as.character(effect.metric)) %>% 
   mutate(effect.metric = replace_na(effect.metric,"not_available")) %>% 
  # make new column for each polymer type for relative percentage
  #filter(effect.metric != "not_available") %>% 
  #filter(exposure.route == "water") %>% 
  mutate(effect.metric = as.factor(effect.metric)) %>% 

#mutate_if(~is.numeric(.) && (.) > 0, log10) %>% 
  # mutate(effect_10 = case_when( #convert ordinal to numeric
  #     effect == "Y" ~ 1,
  #     effect == "N" ~ 0
  #   )) %>%
  # mutate(effect_10 = factor(effect_10)) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::select(-c(rowid, EVA,
                   lvl2_f_frac,
                   #LTX,
                   PA, PC, PE, PET, PLA, PMMA, PP, PS, PUR, PVC, fiber, fragment, sphere)) %>% 
   drop_na()  #drop missing

#ensure completeness
skim(df_oxidative.stress)
```

#### Train models
##### Split data
```{r}
# create train, validation, and test splits
# Create calibration and validation splits with tidymodels initial_split() function.
set.seed(4)
df_split <- df_oxidative.stress %>%
  initial_split(prop = 0.75)
# default is 3/4ths split (but 75% training, 25% testing).

# Create a training data set with the training() function
# Pulls from training and testing sets created by initial_split()
train <- training(df_split)
test <- testing(df_split)

# variable names for response & features
y <- "particles.mL.ox.stress"
x <- setdiff(names(df_oxidative.stress), y) 

## subset for ebm syntax
train_x <- as.data.frame(train %>% dplyr::select(- particles.mL.ox.stress))
train_y <- as.numeric(as.vector(train$particles.mL.ox.stress))

test_x <- as.data.frame(test %>% dplyr::select(- particles.mL.ox.stress))
test_y <- as.numeric(as.vector(test$particles.mL.ox.stress))
```

##### Build GLM, RF, EBM
```{r}
###build explainable boosting machine model #####
# ebm_oxidative.stress <- ebm_classify(train_x, #features
#                     train_y, #target,
#                             ## hyper-parameters, currently in default state:
#                             max_bins = 255,
#                             outer_bags = 16,
#                             inner_bags = 0,
#                             learning_rate = 0.01,
#                             validation_size = 0.15,
#                             early_stopping_rounds = 50,
#                             early_stopping_tolerance = 1e-4,
#                             max_rounds = 5000,
#                             max_leaves = 3,
#                             min_samples_leaf = 2,
#                             random_state = 42)

#####build additional models using caret package and expain using DALEX package #####
classif_rf_oxidative.stress <- train(particles.mL.ox.stress ~ ., data = train, method = "rf", ntree = 100, tuneLength = 1)
classif_xgbTree_oxidative.stress <- train( particles.mL.ox.stress~., data = train, method = "xgbTree")#, preProcess = c("scale","center"))
#classif_nnet_oxidative.stress <- train(particles.mL.ox.stress ~., data = train, method = "nnet")
classif_glm_oxidative.stress <- train(particles.mL.ox.stress ~., data = train, method = "lm")
```

##### Model diagnostics
```{r}
##### build explainers ####
# extract test data#
yTest <- as.numeric(as.character(test$particles.mL.ox.stress))

explainer_classif_rf_oxidative.stress <- DALEX::explain(classif_rf_oxidative.stress,
                                       label = "rf",
                                       data = test_x, 
                                       y = yTest)

explainer_classif_xgbTree_oxidative.stress <- DALEX::explain(classif_xgbTree_oxidative.stress,
                                       label = "xgbTree",
                                       data = test_x,
                                       y = yTest)
                                       
explainer_classif_glm_oxidative.stress <- DALEX::explain(classif_glm_oxidative.stress, label = "glm", 
                                        data = test_x, y = yTest)

#explainer_classif_nnet_oxidative.stress <- DALEX::explain(classif_nnet_oxidative.stress, label = "nnet", 
 #                                       data = test_x, y = yTest)
### EBM model ###
#proba_test_oxidative.stress <- ebm_predict_proba(ebm_oxidative.stress, test_x) #keeps giving NA's for some reason...

#### Caret models ####
mp_classif_rf_oxidative.stress <- model_performance(explainer_classif_rf_oxidative.stress)
mp_classif_xgbTree_oxidative.stress <- model_performance(explainer_classif_xgbTree_oxidative.stress)
mp_classif_glm_oxidative.stress <- model_performance(explainer_classif_glm_oxidative.stress)
#mp_classif_nnet_oxidative.stress <- model_performance(explainer_classif_nnet_oxidative.stress)

plot(mp_classif_rf_oxidative.stress, mp_classif_glm_oxidative.stress, mp_classif_xgbTree_oxidative.stress
     #, mp_classif_nnet_oxidative.stress
)
```
```{r}
plot(mp_classif_rf_oxidative.stress, mp_classif_glm_oxidative.stress, mp_classif_xgbTree_oxidative.stress,
     #mp_classif_nnet_oxidative.stress, 
     geom = "boxplot")
```
```{r}
resid <- rbind(mp_classif_rf_oxidative.stress$residuals, mp_classif_glm_oxidative.stress$residuals, mp_classif_xgbTree_oxidative.stress$residuals)

resid %>% 
ggplot(aes(x = diff, y = label, fill = label)) +
  geom_boxplot() +
  scale_x_log10() +
  scale_fill_tron(name = "Model",
                  labels = c("Extreme Gradient Boosting Trees", "Random Forest", "Linear Model")) +
  labs(title = "Model Performance",
       subtitle = "Residuals") +
  theme.type +
  color.type

```


###### R-squared
```{r}
tibble(mp_classif_glm_oxidative.stress$measures$r2, mp_classif_rf_oxidative.stress$measures$r2, mp_classif_xgbTree_oxidative.stress$measures$r2#,
       #mp_classif_nnet_oxidative.stress$measures$r2
       )
```

###### RoC Curves
```{r eval=FALSE, include=FALSE}
#plot ROC curves
plot(mp_classif_rf_oxidative.stress, 
     mp_classif_glm_oxidative.stress, 
     geom = "roc") +
  ggtitle("ROC Curves - All Models",  
          paste("AUC_rf = ",round(mp_classif_rf_oxidative.stress$measures$auc,3), 
                paste("AUC_glm = ",round(mp_classif_glm_oxidative.stress$measures$auc,3))
          )) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```
##### Recursive Feature Elimination

*WARNING* This chunk takes a very long time to run!
```{r Recursive Feature Elimination, eval=FALSE, include=FALSE}
#first we need to remove species with just a single data point because we need less than 53 levels
n_species <- train %>% group_by(species_f) %>% summarize(count = n())
train_trim <- left_join(train, n_species) %>% 
  filter(count >= 5) %>% 
  #dplyr::select(-lvl2_f) %>% 
  droplevels()

my_ctrl <- rfeControl(functions = rfFuncs, #random forests
                      method = "repeatedcv",
                      verbose = FALSE,
                      repeats = 5,
                      returnResamp = "all")

rfProfile <- rfe(y = train_trim$particles.mL.ox.stress, # set dependent variable
              x = train_trim %>% 
                dplyr::select(-particles.mL.ox.stress),
              rfeControl = my_ctrl,
               size = c(1:4, 8, 12, 16, 20, 24, 27))
rfProfile
```

###### Predictor Selection
The following variables are those that were picked in the final (most accurate) model. 
```{r eval=FALSE, include=FALSE}
#get variable names picked in the final model
predictors(rfProfile)
```
The first 6 models are shown below with their corresponding accuracy and kappa values. 
```{r eval=FALSE, include=FALSE}
head(rfProfile$resample)
```

```{r eval=FALSE, include=FALSE}
trellis.par.set(caretTheme())
plot(rfProfile, type = c("g", "o"), metric = "Rsquared")
#ggplot(rfProfile) + theme_bw()
```
```{r eval=FALSE, include=FALSE}
plot1 <- xyplot(rfProfile, type = c("g", "p", "smooth"), main = "Accuracy of individual resampling results")
plot2 <- densityplot(rfProfile, 
                     subset = Variables < 5, 
                     adjust = 1.25, 
                     as.table = TRUE, 
                     xlab = "Accuracy Estimates", 
                     pch = "|")
print(plot1, split=c(1,1,1,2), more=TRUE)
print(plot2, split=c(1,2,1,2))
```

###### Final Predictor Selection
```{r eval=FALSE, include=FALSE}
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 0.01, maximize = TRUE)
# higher tol (~10) gives you less variables
# lower tol (~1) gives you more variables - "I'd like the simplest model within 1% of the best model."
accuracy1 <- pickVars(rfProfile$variables, size = my_size)
accuracy1
```
A random forest model with the above four predictors is within 1% of the best model. If a more accurate model is desired, and data is available, additional factors can be included in the model. Shown below are factors that should be included for a model that is within 0.5% accuracy of the best model.

```{r eval=FALSE, include=FALSE}
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 0.05, maximize = TRUE)
# higher tol (~10) gives you less variables
# lower tol (~1) gives you more variables - "I'd like the simplest model within 1% of the best model."
accuracy0.5 <- pickVars(rfProfile$variables, size = my_size)
accuracy0.5
```
Below is a table showing which variables are included in models of varying accuracies.

```{r eval=FALSE, include=FALSE}
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 0.1, maximize = TRUE)
accuracy0.1 <- pickVars(rfProfile$variables, size = my_size)
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 0.3, maximize = TRUE)
accuracy0.3 <- pickVars(rfProfile$variables, size = my_size)
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 5, maximize = TRUE)
accuracy5 <- pickVars(rfProfile$variables, size = my_size)
my_size <- pickSizeTolerance(rfProfile$results, metric = "Rsquared", tol = 10, maximize = TRUE)
accuracy10 <- pickVars(rfProfile$variables, size = my_size)

varsTable = list('0.1%' =accuracy0.1, '1%' = accuracy1, '5%' = accuracy5, '10%' = accuracy10)

#$make padded dataframe
na.pad <- function(x,len){
    x[1:len]
}

makePaddedDataFrame <- function(l,...){
    maxlen <- max(sapply(l,length))
    data.frame(lapply(l,na.pad,len=maxlen),...)
}
#fancy print
kable(makePaddedDataFrame(
  list('Rsquared (0.1)' = accuracy0.1, 'Rsquared (0.3)' = accuracy0.3, "Rsquared (1)" = accuracy1, 'Rsquared (5)' = accuracy5, 'Rsquared (10)' = accuracy10)
  ),
      caption = "Variables to include in Random Forest to achieve Rsquared (within x% of best model)",
    footnote = "Random Forest Recursive Feature Elimination")
```


#### Interpretation
##### Variable Importance
```{r fig.height=7, fig.width=5, warning=FALSE}
vi_classif_rf_oxidative.stress <- model_parts(explainer_classif_rf_oxidative.stress, loss_function = loss_root_mean_square)
vi_classif_glm_oxidative.stress <- model_parts(explainer_classif_glm_oxidative.stress, loss_function = loss_root_mean_square)
vi_classif_xgbTree_oxidative.stress <- model_parts(explainer_classif_xgbTree_oxidative.stress, loss_function = loss_root_mean_square)

plot(vi_classif_rf_oxidative.stress, 
     vi_classif_xgbTree_oxidative.stress, 
     vi_classif_glm_oxidative.stress
     )
```
```{r}
plot(vi_classif_rf_oxidative.stress)
```

##### Partial Dependence
###### Organism Group and Exposure Duration
```{r}
#Partial Dependence by dose.surface.area.um2.mL.master and bio.org
pdp_classif_rf  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "exposure.duration.d", 
                                 groups = "organism.group")
# #rearrange factors in order
# rf_pdp <- pdp_classif_rf$agr_profiles %>%
#   tibble() %>%
#   arrange(`_yhat_`)
# #change levels
# rf_pdp$`_x_` <- factor(rf_pdp$`_x_`)
# 
# plot(rf_pdp)
#      %>%
#   plot()
#   mutate(bio.org = fct_reorder(`_x_`,`_yhat_`)) %>%
#   ggplot(aes(x = bio.org, y = `_yhat_`, fill= bio.org)) +
#  geom_point() +
#   #geom_
#   #geom_col() +
#   labs(title = "Partial Dependence Profile by Level of Biological Organization",
#        subtitle = "Random Forest") +
#   xlab("Level of Biological Organization") +
#   ylab("Average Prediction for Exposure Concentration (log10(particles/mL))") +
#   #coord_cartesian(ylim = c(3.45, 3.60)) +
#   scale_color_discrete(name = "Model x Level of Biological Organization") +
#   fill.type +
#   dark_theme_bw(base_size = 14) +
#   theme(plot.title = element_text(hjust = 0.5),
#         plot.subtitle = element_text(hjust = 0.5),
#         legend.position = "none")

plot(pdp_classif_rf)
```

```{r}
#Partial Dependence by dose.surface.area.um2.mL.master a
pdp_classif_rf  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "exposure.duration.d")#, 
                                # groups = "organism.group")

plot(pdp_classif_rf)
```

###### Life Stage and Organism Group
```{r}
#Partial Dependence by dose.surface.area.um2.mL.master and bio.org
pdp_classif_rf  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "life.stage")#, 
                               #  groups = "organism.group")
#rearrange factors in order
rf_pdp <- pdp_classif_rf$agr_profiles %>%
  tibble() %>%
  arrange(`_yhat_`)
#change levels
rf_pdp$`_x_` <- factor(rf_pdp$`_x_`)

rf_pdp %>%
  mutate(bio.org = fct_reorder(`_x_`,`_yhat_`)) %>%
  ggplot(aes(x = bio.org, y = `_yhat_`, fill= bio.org)) +
   geom_col() +
  labs(title = "Partial Dependence Profile by Level of Biological Organization",
       subtitle = "Random Forest") +
  xlab("Life Stage") +
  ylab("Average Prediction for Exposure Concentration (log10(particles/mL))") +
  coord_cartesian(ylim = c(3.45, 4.40)) +
  scale_color_discrete(name = "Model x Level of Biological Organization") +
  fill.type +
  theme.type +
  #dark_theme_bw(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "none")

#plot(pdp_classif_rf)
```
###### Bio org and organism group
```{r}
#Partial Dependence by dose.surface.area.um2.mL.master and bio.org
pdp_classif_rf  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "bio.org")#, 
                                # groups = "organism.group")
pdp_classif_glm  <- model_profile(explainer_classif_glm_oxidative.stress, variable = "bio.org")#, 
                                 #groups = "organism.group")
pdp_classif_xgbTree  <- model_profile(explainer_classif_xgbTree_oxidative.stress, variable = "bio.org")#, 
                                 #groups = "organism.group")

#plot together
# glm <- plot(pdp_classif_glm$agr_profiles) +
#   ggtitle("GLM: Partial Dependence Profiles by Taxa and Level of Biological Organization", "") +
#   xlab("Level of Biological Organization") +
#   ylab("Average Prediction for Exposure Concentration (particles/mL)") +
#   coord_cartesian(ylim = c(3.45, 3.60)) +
#   scale_color_discrete(name = "Model x Level of Biological Organization") +
#   theme_minimal() +
#   theme(plot.title = element_text(hjust = 0.5))

#rearrange factors in order
rf_pdp <- pdp_classif_rf$agr_profiles %>% 
  tibble() %>% 
  arrange(`_yhat_`)
#change levels
rf_pdp$`_x_` <- factor(rf_pdp$`_x_`)

rf_pdp %>% 
  mutate(bio.org = fct_reorder(`_x_`,`_yhat_`)) %>% 
  ggplot(aes(x = bio.org, y = `_yhat_`, fill= bio.org)) +
  geom_col() +
  labs(title = "Partial Dependence Profile by Level of Biological Organization",
       subtitle = "Random Forest") +
  xlab("Level of Biological Organization") +
  ylab("Average Prediction for Exposure Concentration (log10(particles/mL))") +
 # coord_cartesian(ylim = c(3.4, 3.55)) +
  scale_color_discrete(name = "Model x Level of Biological Organization") +
  fill.type +
  theme.type +
  #dark_theme_bw(base_size = 15) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "none")

# xgbTree <- plot(pdp_classif_xgbTree$agr_profiles) +
#   ggtitle("GLM: Partial Dependence Profiles by Taxa and Level of Biological Organization", "") +
#   xlab("Level of Biological Organization") +
#   ylab("Average Prediction for Exposure Concentration (particles/mL)") +
#   coord_cartesian(ylim = c(3.45, 3.60)) +
#   scale_color_discrete(name = "Model x Level of Biological Organization") +
#   theme_minimal() +
#   theme(plot.title = element_text(hjust = 0.5))
# #pllot togeher
# grid.arrange(glm, rf, xgbTree)
```


###### Fiber
```{r}
#Partial Dependence by effect metric and Fiber fraction
pdp_classif_rf_fiber  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "fiber_frac", 
                                 groups = "effect.metric")
pdp_classif_glm_fiber  <- model_profile(explainer_classif_glm_oxidative.stress, variable = "fiber_frac", 
                                 groups = "effect.metric")
pdp_classif_xgbTree_fiber  <- model_profile(explainer_classif_xgbTree_oxidative.stress, variable = "fiber_frac", 
                                 groups = "effect.metric")

#plot together
glm_fiber <- plot(pdp_classif_glm_fiber$agr_profiles) +
  ggtitle("Partial Dependence Profiles by Fiber Fraction and Effect Metric", "") +
  xlab("Fiber Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  #scale_y_continuous(trans = "exp", limits = c(.001,2)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

rf_fiber <- plot(pdp_classif_rf_fiber$agr_profiles) +
  ggtitle("Partial Dependence Profiles by Fiber Fraction and Effect Metric", "") +
  xlab("Fiber Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

xgbTree_fiber <- plot(pdp_classif_xgbTree_fiber$agr_profiles) +
  ggtitle("Partial Dependence Profiles by Fiber Fraction and Effect Metric", "") +
   xlab("Fiber Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#pllot togeher
grid.arrange(glm_fiber, rf_fiber, xgbTree_fiber)
```
```{r}
plot(xgbTree_fiber)
```


###### Fragment
```{r}
#Partial Dependence by effect metric and fragment fraction
pdp_classif_rf_fragment  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "fragment_frac", 
                                 groups = "effect.metric")
pdp_classif_glm_fragment  <- model_profile(explainer_classif_glm_oxidative.stress, variable = "fragment_frac", 
                                 groups = "effect.metric")
pdp_classif_xgbTree_fragment  <- model_profile(explainer_classif_xgbTree_oxidative.stress, variable = "fragment_frac", 
                                 groups = "effect.metric")

#plot together
glm_fragment <- plot(pdp_classif_glm_fragment$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by fragment Fraction and Effect Metric", "") +
  xlab("fragment Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  #scale_y_continuous(trans = "exp", limits = c(.001,2)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

rf_fragment <- plot(pdp_classif_rf_fragment$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by fragment Fraction and Effect Metric", "") +
  xlab("fragment Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

xgbTree_fragment <- plot(pdp_classif_xgbTree_fragment$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by fragment Fraction and Effect Metric", "") +
   xlab("fragment Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#pllot togeher
grid.arrange(glm_fragment, rf_fragment, xgbTree_fragment)
```
###### Sphere
```{r}
#Partial Dependence by effect metric and sphere fraction
pdp_classif_rf_sphere  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "sphere_frac", 
                                 groups = "effect.metric")
pdp_classif_glm_sphere  <- model_profile(explainer_classif_glm_oxidative.stress, variable = "sphere_frac", 
                                 groups = "effect.metric")
pdp_classif_xgbTree_sphere  <- model_profile(explainer_classif_xgbTree_oxidative.stress, variable = "sphere_frac", 
                                 groups = "effect.metric")

#plot together
glm_sphere <- plot(pdp_classif_glm_sphere$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by sphere Fraction and Effect Metric", "") +
  xlab("sphere Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  #scale_y_continuous(trans = "exp", limits = c(.001,2)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

rf_sphere <- plot(pdp_classif_rf_sphere$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by sphere Fraction and Effect Metric", "") +
  xlab("sphere Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

xgbTree_sphere <- plot(pdp_classif_xgbTree_sphere$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by sphere Fraction and Effect Metric", "") +
   xlab("sphere Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#pllot togeher
grid.arrange(glm_sphere, rf_sphere, xgbTree_sphere)
```

###### Polyethylene
```{r}
#Partial Dependence by effect metric and PE fraction
pdp_classif_rf_PE  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "PE_frac", 
                                 groups = "effect.metric")
pdp_classif_glm_PE  <- model_profile(explainer_classif_glm_oxidative.stress, variable = "PE_frac", 
                                 groups = "effect.metric")
pdp_classif_xgbTree_PE  <- model_profile(explainer_classif_xgbTree_oxidative.stress, variable = "PE_frac", 
                                 groups = "effect.metric")

#plot together
glm_PE <- plot(pdp_classif_glm_PE$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by PE Fraction and Effect Metric", "") +
  xlab("PE Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  #scale_y_continuous(trans = "exp", limits = c(.001,2)) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

rf_PE <- plot(pdp_classif_rf_PE$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by PE Fraction and Effect Metric", "") +
  xlab("PE Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

xgbTree_PE <- plot(pdp_classif_xgbTree_PE$agr_profiles) +
  ggtitle("GLM: Partial Dependence Profiles by PE Fraction and Effect Metric", "") +
   xlab("PE Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#pllot togeher
grid.arrange(glm_PE, rf_PE, xgbTree_PE)
```
```{r}
#Partial Dependence by effect metric and PE fraction
pdp_classif_rf_PE  <- model_profile(explainer_classif_rf_oxidative.stress, variable = "fiber_frac", 
                                 groups = "effect.metric")


rf_PE <- plot(pdp_classif_rf_PE$agr_profiles) +
  ggtitle("Partial Dependence Profiles by Fiber Fraction and Effect Metric", "") +
  xlab("Fiber Fraction") +
  ylab("Average Prediction for Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))


#pllot togeher
grid.arrange(rf_PE)
```
###### Translocatable
```{r}
#Partial Dependence by effect metric and PE fraction
pdp_classif_rf_translocatable  <- model_profile(explainer_classif_rf_oxidative.stress,
                                                variable = "translocatable", 
                                 groups = "effect.metric"
                                 )

rf_translocatable <- plot(pdp_classif_rf_translocatable$agr_profiles) +
  ggtitle("Partial Dependence Profile by translocatable particles", "") +
  xlab("Translocatable particles") +
  ylab("Average Prediction for Oxidative Stress Exposure Concentration (particles/mL)") +
  scale_color_discrete(name = "Model x Effect Metric") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

rf_translocatable
```

##### LIME (Local Interpretable Model-Agnostic Explanations)
Behind the workings of lime lies the (big) assumption that every complex model is linear on a local scale. While this is not justified in the paper it is not difficult to convince yourself that this is generally sound  you usually expect two very similar observations to behave predictably even in a complex model. lime then takes this assumption to its natural conclusion by asserting that it is possible to fit a simple model around a single observation that will mimic how the global model behaves at that locality. The simple model can then be used to explain the predictions of the more complex model locally.

The general approach lime takes to achieving this goal is as follows:

* For each prediction to explain, permute the observation n times.
* Let the complex model predict the outcome of all permuted observations.
* Calculate the distance from all permutations to the original observation.
* Convert the distance to a similarity score.
* Select m features best describing the complex model outcome from the permuted data.
* Fit a simple model to the permuted data, explaining the complex model outcome with the m features from the permuted data weighted by its     similarity to the original observation.
* Extract the feature weights from the simple model and use these as explanations for the complex models local behavior.


```{r}
require(lime)
model_type.gbm <- function(x, ...) {
  return("regression")
}

predict_model.gbm <- function(x, newdata, ...) {
  pred <- predict(x, newdata, n.trees = x$n.trees)
  return(as.data.frame(pred))
}

# get a few observations to perform local interpretation on
local_obs <- test_x[1:4, ]

# apply LIME
explainer <- lime(train_x, classif_xgbTree_oxidative.stress)
explanation <- lime::explain(local_obs, explainer, n_features = 10, n_labels = 5)
plot_features(explanation, ncol = 2)
```

### Food Dilution
```{r GLM build 2}
require(reshape2)
# data preparation
df_food.dilution <- aoc_final %>% 
 #filter data select predictor variables#
  dplyr::select(c(
    ### DOSE METRICS ####
                 # particles.mL.ox.stress,
                  particles.mL.food.dilution,
                  #dose.mg.L.master, 
                  #dose.surface.area.um2.mL.master, #fibers are assumed to be cylinders, fragments are assumed to be spheres
                  #dose.particles.mL.master, 
    ### Organism characteristics ###
                  life.stage, #use adults for prediction
                  species_f, 
                  max.size.ingest.mm,
                  organism.group, 
    ### Exposure Conditions ####              
                  bio.org, #use tissue and above for lower tiers, organism and above for higher tiers
                  exposure.route, #train on all, but only use "aquatic" for build
                  environment, #train on all, buit only use "marine" for SSD Build
                  acute.chronic_f, #use 'chronic' for SSD build
                  exposure.duration.d, 
    ### Particle characteristics ####
                  polymer, 
                  shape,
                  #density.g.cm3,
                  #size.length.um.used.for.conversions, 
                  translocatable,
    ### Effect data ####
                  #effect, 
                  effect.score,
                  effect.metric, #train on all, but only specify "NOEC" for SSD build
                  lvl1_f, #keep it generic for easy SSD build (use fitness)
                  lvl2_f#,
                 # lvl3_f
                  )) %>% 
   rowid_to_column(var = "rowid") %>% 
  mutate(value = 1) %>% 
   mutate(particles.mL.food.dilution = log10(particles.mL.food.dilution)) %>% 
  ###### create new column for polymer percentage #####
  dcast(... ~ polymer, value.var = c("value")) %>% 
  # provide 0 for all 'na's'
  mutate(across(.cols = last_col() + (-11:0),
                .fns = ~replace(., is.na(.), 0),
                .names = "{.col}_frac")) %>% 
###### create new column for shape percentage #####
mutate(value = 1) %>% 
  dcast(... ~ shape, value.var = c("value")) %>% 
  # not all rows have unique identifiers (basically dupes), so need to eliminate values > 1
  mutate(across(.cols = last_col() + (-2:0),
                .fns = ~replace(., is.na(.), 0),
                .names = "{.col}_frac")) %>% 
  mutate(effect.metric = (case_when(
    effect.metric == "NONEC" ~ "NOEC",
    effect.metric == "HONEC" ~ "NOEC",
    effect.metric == "LOEC" ~ "LOEC",
    effect.metric == "LC50" ~ "LC50",
    effect.metric == "EC50" ~"EC50",
    effect.metric == "EC10" ~ "EC10"
  ))) %>% 
 mutate(effect.metric = as.character(effect.metric)) %>% 
   mutate(effect.metric = replace_na(effect.metric,"not_available")) %>% 
  # make new column for each polymer type for relative percentage
  #filter(effect.metric != "not_available") %>% 
  #filter(exposure.route == "water") %>% 
  mutate(effect.metric = as.factor(effect.metric)) %>% 

#mutate_if(~is.numeric(.) && (.) > 0, log10) %>% 
  # mutate(effect_10 = case_when( #convert ordinal to numeric
  #     effect == "Y" ~ 1,
  #     effect == "N" ~ 0
  #   )) %>%
  # mutate(effect_10 = factor(effect_10)) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::select(-c( rowid, EVA, 
                    #LTX,
                    PA, PC, PE, PET, PLA, PMMA, PP, PS, PUR, PVC, fiber, fragment, sphere,
                    lvl2_f_frac)) %>% 
   drop_na()  #drop missing

#ensure completeness
skim(df_food.dilution)
```

#### Train models
##### Split data
```{r}
# create train, validation, and test splits
# Create calibration and validation splits with tidymodels initial_split() function.
set.seed(4)
df_split <- df_food.dilution %>%
  initial_split(prop = 0.75)
# default is 3/4ths split (but 75% training, 25% testing).

# Create a training data set with the training() function
# Pulls from training and testing sets created by initial_split()
train <- training(df_split)
test <- testing(df_split)

# variable names for response & features
y <- "particles.mL.food.dilution"
x <- setdiff(names(df_food.dilution), y) 

## subset for ebm syntax
train_x <- as.data.frame(train %>% dplyr::select(-particles.mL.food.dilution))
train_y <- as.numeric(as.vector(train$particles.mL.food.dilution))

test_x <- as.data.frame(test %>% dplyr::select(-particles.mL.food.dilution))
test_y <- as.numeric(as.vector(test$particles.mL.food.dilution))
```

#### Build GLM and EBM
```{r}
###build explainable boosting machine model #####
# ebm_food.dilution <- ebm_classify(train_x, #features
#                     train_y, #target,
#                             ## hyper-parameters, currently in default state:
#                             max_bins = 255,
#                             outer_bags = 16,
#                             inner_bags = 0,
#                             learning_rate = 0.01,
#                             validation_size = 0.15,
#                             early_stopping_rounds = 50,
#                             early_stopping_tolerance = 1e-4,
#                             max_rounds = 5000,
#                             max_leaves = 3,
#                             min_samples_leaf = 2,
#                             random_state = 42)

#####build additional models using caret package and expain using DALEX package #####
classif_rf_food.dilution <- train(particles.mL.food.dilution~., data = train, method = "rf", ntree = 100, tuneLength = 1)
classif_xgbTree_food.dilution <- train(particles.mL.food.dilution~., data = train, method = "xgbTree")#, preProcess = c("scale","center"))
classif_glm_food.dilution <- train(particles.mL.food.dilution~., data = train, method = "lm")
```

#### Model diagnostics
```{r}
##### build explainers ####
# extract test data#
yTest <- as.numeric(as.character(test$particles.mL.food.dilution))

explainer_classif_rf_food.dilution <- DALEX::explain(classif_rf_food.dilution,
                                       label = "rf",
                                       data = test_x, 
                                       y = yTest)

explainer_classif_xgbTree_food.dilution <- DALEX::explain(classif_xgbTree_food.dilution, label = "xgbTrees", 
                                        data = test_x, y = yTest)
                                       
explainer_classif_glm_food.dilution <- DALEX::explain(classif_glm_food.dilution, label = "glm", 
                                        data = test_x, y = yTest)
### EBM model ###
#proba_test_food.dilution <- ebm_predict_proba(ebm_food.dilution, test_x) #keeps giving NA's for some reason...

#### Caret models ####
mp_classif_rf_food.dilution <- model_performance(explainer_classif_rf_food.dilution)
mp_classif_xgbTree_food.dilution <- model_performance(explainer_classif_xgbTree_food.dilution)
mp_classif_glm_food.dilution <- model_performance(explainer_classif_glm_food.dilution)
```
###### R-squared
```{r}
tibble(mp_classif_glm_food.dilution$measures$r2, mp_classif_rf_food.dilution$measures$r2, mp_classif_xgbTree_food.dilution$measures$r2#,
       #mp_classif_nnet_food.dilution$measures$r2
       )
```

##### RoC Curves
```{r eval=FALSE, include=FALSE}
#plot ROC curves
plot(mp_classif_rf_food.dilution, 
     mp_classif_glm_food.dilution, 
     geom = "roc") +
  ggtitle("ROC Curves - All Models",  
          paste("AUC_rf = ",round(mp_classif_rf_food.dilution$measures$auc,3), 
                paste("AUC_glm = ",round(mp_classif_glm_food.dilution$measures$auc,3))
          )) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

##### Variable Importance
```{r echo=TRUE, fig.height=7, fig.width=5, warning=FALSE}
vi_classif_rf_food.dilution <- model_parts(explainer_classif_rf_food.dilution, loss_function = loss_root_mean_square)
vi_classif_glm_food.dilution <- model_parts(explainer_classif_glm_food.dilution, loss_function = loss_root_mean_square)
vi_classif_xgbTree_food.dilution <- model_parts(explainer_classif_xgbTree_food.dilution, loss_function = loss_root_mean_square)

plot(vi_classif_rf_food.dilution, vi_classif_glm_food.dilution, vi_classif_xgbTree_food.dilution)
```





# Resources: 
https://pubs.acs.org/doi/suppl/10.1021/acs.est.0c02982/suppl_file/es0c02982_si_001.pdf https://pubs.acs.org/doi/suppl/10.1021/acs.estlett.9b00379/suppl_file/ez9b00379_si_001.pdf
https://pubs.acs.org/doi/10.1021/acs.estlett.9b00379


# Particles constant, volume different
## Generate Particles

Shape is defined as:
Simplifed equation for corey shape factor:

$CSF = H/sqrt(LW)$

Equation for abundance of particles based on density (two distributions). (Note that this is *equation 4* in Kooi and Koelmans (2019).)

The most abundant shape category of microplastic in water and sediment is fibers (48.5%), followed by fragments (31%), beads (6.5%), films (5.5%), and foam (3.5%)(3). Combining these abundance data with the triangular shape distributions (Table S2 and Figure S2) resulted in a continuous bimodal microplastic shape distribution (Figure 2A). The fitted parameter values for eq 4 were as follows: f1 = 0.06, f2 = 0.94, 1 = 0.03, 2 = 0.19, 1 = 0.08, and 2 = 0.44 (see Table S5 for standard errors). A Pearson 2 test indicated that the optimized distribution fits the data well (the fitted model did not differ significantly from the data; p = 0.231 > 0.05). The distribution is dominated by fibers and fragments (CSF = 0.250.75) but also has a distinct second peak at a CSF of 0.07, which is mainly attributed to sheets (Figure 2A). The distribution captures the main features of shapes encountered in the environment as well as the relative abundances of these (now continuous) shapes in one go. Most illustrative though is the continuous character of microplastic shape.

$y = f1(\frac{1}{sqrt(2pi()\sigma_1^2})e^{-(x-\mu_1)^2/2\sigma_1^2} + f2(\frac{1}{sqrt(2pi()\sigma_2^2})e^{-(x-\mu_2)^2/2\sigma_2^2}$

For polymer abundance, for the K&K2019 paper I used the fixed values from Burns & Boxall review, and went straight for density. Given these fixed relative abundances, you could calculate polymer type randomly for N particles via: 

pols <- c("PE", "PP", "PS")
rel.ab <- c(0.5, 0.3, 0.2)
n = 1000
sample(pols, size = n, prob = rel.ab, replace = TRUE)

Particle volume is determined according to shape as follows:

$V = \frac{\pi}{6}L^3CSF^2$

Where CSF = corey shape factor and L = length.

Particle mass is estimated as follows:

$m = pV*\frac{1}{1e12}*1000$

Where *m* is the mass (mg), *p* is density (g/cm^3), *V* is volume (um^3) - which is calculated by the cube of the length (um) of each particle, and additional conversion factors for mg to g (x1000) and cm^3 to um^3 (1e-12).
```{r}
#variables to set for funcions
      xmin = 1 #UM
      alpha = alpha #2.07 is preferred in unpublished Kooi et al.
      
      mu1 <- 0.08
      mu2 <- 0.44
      sd1 <- 0.03
      sd2 <- 0.19
      lambda1 <- 0.06
      lambda2 <- 0.94
        
      d.alpha = 73.8 #tail heaviness
      d.beta = 69.9  #asymmetry
      d.mu = 0.840   #location
      d.delta = 0.0972 #scale
X.func <- function (X){
  success <- FALSE
  while (!success){
    U = runif(1, 0, 1)
    X = xmin*(1-U)^(1/(1-alpha))
    success <- X < 5000} ##should be smaller than 5000 um 
  return(X)
}
D.func <- function (D){
  success <- FALSE
  while (!success){
    D = rnig(1, mu = d.mu, alpha = d.alpha, beta = d.beta, delta = d.delta)
    success <- D < 2.63} ## include upper limit of 2.63, the max. 
  return(D)
}
synthetic_distributed_data_builder <- function(count, volume_l){#, addedfactors){
  #Preset parameters for pdfs
   ## Generate values for the three distributions
      set.seed(123)
      Data <- data.frame(Size = numeric(0))
      
      for(i in 1:count){
        X <- X.func()
        Data <- rbind(Data, X)
      }
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## SIZE DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      colnames(Data) <- c("Size")
      
      #min(Data$Size) ##20 um
      #max(Data$Size) ##5000 um
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## SHAPE DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      #Sample N random uniforms U
      U =runif(count)
      
      #Sampling from the mixture
      for(i in 1:count){
        if(U[i]<lambda1){
          Data$Shape[i] = rtnorm(1,mu1,sd1, lower = 0, upper = 1)
        }else{
          Data$Shape[i] = rtnorm(1,mu2,sd2, lower = 0, upper = 1)
        }
      }
      
      min(Data$Shape) ##0
      max(Data$Shape) ##1
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## DENSITY DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      Dens <- data.frame(Density = numeric(0));
      
      for(i in 1:count){
        X <- D.func()
        Dens <- rbind(Dens, X)
      }
      
      colnames(Dens) <- c("Density")
      
      Data <- cbind(Data, Dens)
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## Polymer DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      pols <- c("PE", "PP", "PS")
      rel.ab <- c(0.5, 0.3, 0.2)
      polymer <- sample(pols, size = count, prob = rel.ab, replace = TRUE)
      Data <- cbind(Data, polymer)
      
      Data %>%  
        mutate(size.category = factor(case_when(
          Size < 10 & Size >= 1 ~ "1m < 10m",
          Size < 100 & Size >= 10 ~ "10m < 100m",
          Size < 1000 & Size >= 100 ~ "100m < 1mm",
          Size < 5000 & Size >= 1000 ~ "1mm < 5mm"))) %>% 
        mutate(mass.mg = Density * Size^3 * 1E-9) %>% 
        mutate(um3 = (Size^3)) %>%
        #bind_cols(addedfactors[rep(1, times = nrow(.)),]) %>% 
        mutate(vol.L = volume_l) %>% 
        mutate(vol.mL = vol.L * 1000) %>% 
        mutate(dose.um3.mL.master = um3 / vol.mL) %>% 
        mutate(dose.particles.mL.master = 1 / vol.mL) %>% 
        mutate(dose.mg.L.master = mass.mg / vol.L) %>% 
        mutate(particles.total = factor(as.character(count)))
}
add_prediction <- function(fun, model, ...){
        fun(...) %>%
        mutate_if(~is.numeric(.) && (.) > 0, log10) %>%
        bind_cols(predict(model, newdata = ., type = "prob") %>% 
        rename("ToxicityProbability" = `1`))                  
}
```


Test synthetic data.
```{r}
count10000 <- synthetic_distributed_data_builder(count = 10000, 
                                    volume_l = 1
                                    )
#collapse dataframe into single row with summary statistics
#count10000 %>% 

```


```{r}
##++++++++++++++++++++++++++++++++++++++++
## Quick check results
##++++++++++++++++++++++++++++++++++++++++
skim(synthetic_distributed_data_builder(count = 10000, 
                                    volume_l = 1#, 
                               #     addedfactors = possible_variables[488,]
                                    ))
```


### Uniform Distribution

It may be possible to visualize discrete relationships of toxicity by creating a uniform distribution of particles within the parameter space of the training dataset, then plotting the predicted toxicities for different predictors.

#### Generate uniform particles
```{r}
n = 1000
#Create uniform characteristics for base particle characteristics (size, shape, density)
csf <- runif(n, min = min(aoc_z$csf, na.rm = T), max(aoc_z$csf, na.rm = T)) #Set this to parameter space 
#mass.per.particle.mg <- runif(n, min = 0, max = 1.65e+1)
density.mg.um.3 <- runif(n, min = min(aoc_z$density.mg.um.3, na.rm = T), max = max(aoc_z$density.mg.um.3, na.rm = T))
size.length.um.used.for.conversions <- runif(n, min = min(aoc_z$size.length.um.used.for.conversions, na.rm = T), max = max(aoc_z$size.length.um.used.for.conversions, na.rm = T))
#create uniform distribution of polymer types
#pols <- c("PE", "PP", "PS", "PVC", "PET")
#rel.ab <- c(0.2, 0.2, 0.2, 0.2, 0.2)
#polymer <- sample(pols, size = n, prob = rel.ab, replace = TRUE)
#create data frame with uniform distirbutions
unif_df <- data.frame(csf, density.mg.um.3, size.length.um.used.for.conversions) %>%
  mutate(mass.per.particle.mg = density.mg.um.3 * size.length.um.used.for.conversions ^ 3 * 1E-9) %>% 
  mutate(particle.volume.um3 = pi/6 * (size.length.um.used.for.conversions ^ 3) * csf ^2 ) %>% #equation 4
  #volume
  mutate(vol.mL = 0.0001) %>% 
  mutate(vol.L = vol.mL / 1000) %>%  
  mutate(dose.um3.mL.master = particle.volume.um3 / vol.mL) %>% 
  mutate(dose.particles.mL.master = 1 / vol.mL) %>% 
  mutate(dose.mg.L.master = mass.per.particle.mg / vol.L) %>% 
    #organism/test system characteristics
  mutate_if(is.character, as.factor)
skim(unif_df)
```
HIGHLIGHT AREA UNDER THE CURVE
If we go down to lower number, we would not adequately mimic distribution. Stick to creating 1E5 particles, then change volume. 
Could capture variability for small bumbers by simulating small number of particles


How to calculate uncertainties? 
  Replace effect parameters by median +- SD, then predict tox for each distribution, plot, then if it is minor, FORGET about it! REsiduals in Merel's models were not randomly distributed -  so imperfect models.
  
What sizes should be used?
  1-5,000 um. 

Wait for Merel to update interactions between shape/size/density/count.
  
What about max size ingest?
  Tox studies typically do not exposure animals to particles bigger than their mouth size opening, so model may not understand that relationship. 
  Could impose bioavailable fraction AFTER model. JUST do predictions for species that have bioavailable fraction data. Could estimate mouth size from prey to predator fraction. JAMS et al has mouth-size opening parameters.

Non-linear regression to get dose-response. 

Mattson, Hasselof, Frontiers in Science - measures size distribution. 

Final figure: SINGLE toxicity prediction for each dose. Use environmental data. Make SSD. Risk Characterization. The model's SSD is fundamentally different from the SSD made from monodisperse particles, so it is MORE reliable. 
Big assumption: all particle toxicities are ADDITIVE! Depends on effect mechanism - food dilution. 


# Dose-response curves

```{r}
SSD_function_t1 <- function(filtered.data, hcxlcl){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.50))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, ic = "aicc", nboot = 10, ci= TRUE) 
#
ssd_frame <- collapsed[order(collapsed$Conc), ]
ssd_frame$frac <- ppoints(collapsed$Conc, 0.5)
#report HC metrics of interest
hc5lcl <- c(preds$lcl[hcxlcl]) #CI95
#values to extract
#print(hc5lcl)
return(list(preds, ssd_frame))
}
```

Part of me just wants to set the uniform distribution to the distinct version of the dataset. That way we can define uncertainty for each dose response curve and are not extrapolating within ranges (sometimes people just get data for the max and min in a distribution that doesn't mean that we know what the middle should be.)

### COMPOSITION
#### Polymer/Shape Agnostic
By commenting out translocatable below, I can specify it for oxidative stress, which allows me to increase the number of species that feeds into the SSD. I can't do this for food dilution however.
```{r}
#define base parameters for all SSDs
composition_agnostic <- df_oxidative.stress %>% 
  # make entry for each species
  distinct(species_f, max.size.ingest.mm, life.stage, bio.org, lvl1_f, lvl2_f, 
           #lvl3_f, 
           exposure.duration.d, organism.group, effect.metric, effect.score,
           acute.chronic_f, environment,  exposure.route, 
           #translocatable,
           # make synonymous with training data for true comparison
          EVA_frac,
          #LTX_frac,
          PA_frac, PC_frac, PE_frac, PET_frac, PLA_frac, PMMA_frac, PP_frac, PS_frac, PUR_frac, PVC_frac, fiber_frac,       fragment_frac, sphere_frac
           ) %>% 
  #give summary statistics for typical composition of 1-5,000 um particle distribution in aquatic environment
  mutate(
  #       EVA_frac = 0.06,
  #       LTX_frac = 0,
  #       PA_frac = 0.12,
  #       PC_frac = 0,
  #       PE_frac = 0.25,
  #       PET_frac = 0.165,
  #       PLA_frac = 0,
  #       PMMA_frac = 0,
  #       PP_frac = 0.145,
  #       PS_frac = 0.085,
  #       PUR_frac = 0,
  #       PVC_frac = 0.02,
  #       fiber_frac = 0.485 * 1.1627, #correction factor to get to 100% because training data doesn't have film
  #       fragment_frac = 0.31 * 1.1627,
  #       sphere_frac = 0.065 * 1.1627,
  #effect = "N",
  #common metrics for all SSDs
  #lvl1_f = "Fitness",
 # life.stage = "Adult",
 # exposure.route = "water",
 # environment = "Marine",
  #acute.chronic_f = "Chronic",
  #effect.metric = "NOEC"
  ) %>% 
  mutate(af.time = case_when(acute.chronic_f == "Chronic" ~ 1,
                             acute.chronic_f == "Acute" ~ 10)) %>% 
  mutate(af.noec = case_when(effect.metric == "HONEC" ~ 1,
                             effect.metric == "LOEC" ~ 2,
                             effect.metric == "EC10" ~ 1,
                             effect.metric == "EC50" ~ 10,
                             effect.metric == "LC50" ~ 10)) %>% 
  drop_na()
```

#### Realistic Polymers and Shapes in Environment
Abundance of most commonly found polymers based on Table S3 of kooi and Kolemans 2019. Shape abundance based on the main text of Kooi and Koelmans 2019. Since there are no training data for films (5.5% in envirnoment) or foam (3.5% in environment), they were omitted from this synthetic dataset and all other categories were increased by a factor of 1.16 to reach 100%. https://pubs.acs.org/doi/suppl/10.1021/acs.estlett.9b00379/suppl_file/ez9b00379_si_001.pdf
```{r}
#define base parameters for all SSDs
composition_realistic <- df_oxidative.stress %>% 
  # make entry for each species
  distinct(species_f, max.size.ingest.mm, life.stage, bio.org, lvl1_f, lvl2_f,
           effect.score,
           effect.metric,
           #lvl3_f, 
           exposure.duration.d, 
           organism.group,
           #effect.metric,
           acute.chronic_f, 
           environment,
           exposure.route, 
           #translocatable,
           # make synonymous with training data for true comparison
          # EVA_frac, LTX_frac, PA_frac, PC_frac, PE_frac, PET_frac, PLA_frac, PMMA_frac, PP_frac, PS_frac, PUR_frac, PVC_frac, fiber_frac,       fragment_frac, sphere_frac
           ) %>% 
  #give summary statistics for typical composition of 1-5,000 um particle distribution in aquatic environment
  mutate(
        EVA_frac = 0.06,
        LTX_frac = 0,
        PA_frac = 0.12,
        PC_frac = 0,
        PE_frac = 0.25,
        PET_frac = 0.165,
        PLA_frac = 0,
        PMMA_frac = 0,
        PP_frac = 0.145,
        PS_frac = 0.085,
        PUR_frac = 0,
        PVC_frac = 0.02,
        fiber_frac = 0.485 * 1.1627, #correction factor to get to 100% because training data doesn't have film
        fragment_frac = 0.31 * 1.1627,
        sphere_frac = 0.065 * 1.1627,
  #effect = "N",
  #common metrics for all SSDs
  #exposure.route = "water",
  #make distinct above instead of forcing here
  #environment = "Marine",
  #acute.chronic_f = "Chronic",
 # effect.metric = "NOEC"
  ) %>% 
  mutate(af.time = case_when(acute.chronic_f == "Chronic" ~ 1,
                             acute.chronic_f == "Acute" ~ 10)) %>% 
  mutate(af.noec = case_when(effect.metric == "HONEC" ~ 1,
                             effect.metric == "LOEC" ~ 2,
                             effect.metric == "NOEC" ~ 1,
                             effect.metric == "EC10" ~ 1,
                             effect.metric == "EC50" ~ 10,
                             effect.metric == "LC50" ~ 10,
                             #effect.metric == "not_available" ~ 1
                             )) %>% 
  drop_na()

skim(composition_realistic)
```
## Oxidative Stress
### Tier 1/2
#### Polymer/Shape Agnostic
```{r}
#Get organism group for each species
groups <- aoc_final %>% 
  distinct(species_f, Group)

#assign groups
ox.1 <- composition_agnostic %>% 
  mutate(translocatable = "translocatable") %>% 
  left_join(groups)
  
# predict NOEC
ox.1$particles.mL.ox.stress_log10 <- predict(classif_rf_oxidative.stress, ox.1, type = "raw")

#Data collapse
ox1.summary <- ox.1 %>%
  rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
  #filter(organism.group != "Algae") %>%
  filter(#environment == "Marine",
         exposure.route == "water",
         translocatable == "translocatable"#,  # 1- 83 um
       #  lvl1_f %in% c("Fitness")
       ) %>%  
  mutate(particles.mL.ox.stress = (10 ^ particles.mL.ox.stress_log10) / (af.time * af.noec)) %>%  
  summarise(dose_new = quantile(particles.mL.ox.stress, 0.50)) #convert from log10

## SSD build
ox.t1.ssd <- SSD_function_t1(filtered.data = ox1.summary, hcxlcl = 5)

#extract data frames from object
ox.t1.preds.agnostic <- as.data.frame(ox.t1.ssd[1])
ox.t1.points.agnostic <- as.data.frame(ox.t1.ssd[2])

#ggplot
ggplot(ox.t1.preds.agnostic, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t1.points.agnostic,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t1.points.agnostic, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution (Polymer/Shape Agnostic)",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

#####Comparison to empirical
###### Empirical alone
```{r}
ox.1.emp <- aoc_final %>%
  #use same data categories as assigned above for prediction in model. NOTE this is different from thresholds derived in main assessment
  filter(#environment == "Marine",
         exposure.route == "water",
        # lvl1_f == "Fitness", #keep constant
         translocatable == "translocatable") %>%  # 1- 83 um
      mutate(dose_new = particles.mL.ox.stress / (af.time * af.noec)) %>% #converts effect metrics to NOECs and exposures to chronic
         drop_na(dose_new) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(dose_new, 0.50))

## SSD build
ox.t1.emp.ssd <- SSD_function_t1(filtered.data = ox.1.emp, hcxlcl = 5)

#extract data frames from object
ox.t1.emp.preds <- as.data.frame(ox.t1.emp.ssd[1])
ox.t1.emp.points <- as.data.frame(ox.t1.emp.ssd[2])

#ggplot
ggplot(ox.t1.emp.preds, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t1.emp.points,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```
##### Overlay
```{r}
# give uniq id
t1.x.e <- ox.t1.emp.preds %>% 
  mutate(type = "Empirical")
t1.x.p <-  ox.t1.preds.agnostic %>% 
  mutate(type = "Predicted")
t1.x.1.e <- ox.t1.emp.points %>% 
  mutate(type = "Empirical") 
t1.x.1.p <-  ox.t1.points.agnostic %>% 
  mutate(type = "Predicted")
#join dataframes
t1.ox.preds.j <- rbind(t1.x.e, t1.x.p)
t1.ox.points.j <- rbind(t1.x.1.e, t1.x.1.p)

#ggplot
ggplot() +#, aes_string(x = "est")) +
  geom_xribbon(data = t1.ox.preds.j, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.4) +
  geom_line(data = t1.ox.preds.j, aes_string(x = "est", y = "percent/100", fill = "type")) +
  geom_point(data = t1.ox.points.j, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = ox.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution (polymer/shape - agnostic)",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type #user theme
```
##### Residuals
```{r}
# give uniq id
t1.x.e <- ox.t1.emp.preds %>% 
  mutate(type = "Empirical")
t1.x.p <-  ox.t1.preds.agnostic #%>% 
  # mutate(type = "Predicted") %>% 
  # mutate(est = est/1000) %>% 
  # mutate(lcl = lcl/1000) %>% 
  # mutate(ucl = ucl/1000)

#plot residuals
t1.x.1.e <- ox.t1.points.agnostic %>% 
  mutate(type = "Empirical") %>% 
  mutate(Conc.e= Conc)
t1.x.1.p <-  ox.t1.emp.points %>% 
  mutate(type = "Predicted")
###join dataframes
#t1.ox.preds.j <- rbind(t1.x.e, t1.x.p)
compare <- left_join(t1.x.1.e, t1.x.1.p, by = "Species") %>% 
    mutate(diff = Conc.e - Conc.y)

# Make color scale for speceis on y axis
# library(scales)
# numColors <- length(levels(compare$Group.x)) # How many colors you need
# getColors <- scales::brewer_pal(name = "Dark2") # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)
# myPalette <- getColors(n = 13)#numColors)
# names(myPalette) <- levels(compare$Group.x) # Give every color an appropriate name

#library(RColorBrewer)
#brewer.pal(n = 13, name = "Dark2")

## Plot Residuals
compare %>% 
  mutate(Species = fct_reorder(Species, abs(diff))) %>% 
  ggplot(aes(x = -log10(abs(diff)), y = Species, color = Group.x)) +
 # geom_boxplot() +
  geom_boxplot(fill = "red", color = "black") +
  geom_point(size = 2.5) +
 # scale_x_log10() +
 # scale_x_continuous(limits = c(-1,10)) +
  labs(title = "Residuals for Predicted NOECs"#,
     # subtitle = "Random Forest Predicted NOECs"
       ) +
  xlab("Empirical - Predicted NOEC (log10 scale)") +
  ylab("Species") +
  geom_vline(xintercept = 0, linetype = "dashed", size = 1.5, alpha = 0.4) +
 # scale_color_manual(values = rainbow(13)) +
  #scale_color_brewer()
  scale_color_futurama(name = "Taxa") +
 # coord_trans(x = "log10") +
 theme.type +
  # dark_theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)#,
#    axis.text.y = element_text(colour=rainbow(13)[compare$Group.x])
    )


#t1.ox.points.j <- rbind(t1.x.1.e, t1.x.1.p)
```
```{r eval=FALSE, include=FALSE}
compare %>% 
  #group_by(Group.x) %>% 
  ggplot(aes(x = diff, y = Group.x)) +
  geom_boxplot() +
  #geom_point() +
  scale_x_continuous(limits = c(-100000,10000)) +
  # coord_trans(x = "log10") +
  #scale_x_log10(limits = c(-50000000,50000000)) +
  theme.type
```
#### Realistic Environmental Polymers and Shapes
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
ox.1.real <- composition_realistic %>% 
  left_join(groups) %>% 
  mutate(translocatable = "translocatable")
  
# predict NOEC
ox.1.real$particles.mL.ox.stress_log10 <- predict(classif_rf_oxidative.stress, ox.1.real, type = "raw")

#Data collapse
ox1.summary.real <- ox.1.real %>%
  filter(#environment == "Marine",
         exposure.route == "water",
         lvl1_f == "Fitness", #keep constant
         translocatable == "translocatable") %>%  # 1- 83 um
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
   mutate(particles.mL.ox.stress = (10 ^ particles.mL.ox.stress_log10) / (af.time * af.noec)) %>% 
  summarise(dose_new = quantile(particles.mL.ox.stress, 0.50)) 


## SSD build
ox.t1.ssd.real <- SSD_function_t1(filtered.data = ox1.summary.real, hcxlcl = 5)

#extract data frames from object
ox.t1.preds.real <- as.data.frame(ox.t1.ssd.real[1])
ox.t1.points.real <- as.data.frame(ox.t1.ssd.real[2])

#ggplot
ggplot(ox.t1.preds.real, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t1.points.real,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t1.points.real, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution (Realistic Shapes and Polymers)",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

#####Comparison to empirical

##### Overlay
```{r}
# give uniq id
t1.x.e <- ox.t1.emp.preds %>% 
  mutate(type = "Empirical")
t1.x.p.real <-  ox.t1.preds.real %>% 
  mutate(type = "Predicted")
t1.x.1.e <- ox.t1.emp.points %>% 
  mutate(type = "Empirical") 
t1.x.1.p.real <-  ox.t1.points.real %>% 
  mutate(type = "Predicted")

#join dataframes
t1.ox.preds.j.real <- rbind(t1.x.e, t1.x.p.real)
t1.ox.points.j.real <- rbind(t1.x.1.e, t1.x.1.p.real)

#ggplot
ggplot() +#, aes_string(x = "est")) +
  geom_xribbon(data = t1.ox.preds.j.real, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.4) +
  geom_line(data = t1.ox.preds.j.real, aes_string(x = "est", y = "percent/100", fill = "type")) +
  geom_point(data = t1.ox.points.j.real, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = ox.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution (Realistic Environmental Polymers and Shapes)",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type #user theme
```

##### Comparison of Realistic, empirical, and Agnostic SSDs
```{r}
# give uniq id
t1.x.p.agnostic <-  ox.t1.preds.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic")
t1.x.p.real <-  ox.t1.preds.real %>% 
  mutate(type = "Environmentally Realistic")
t1.x.1.p.agnostic <- ox.t1.points.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic") 
t1.x.1.p.real <-  ox.t1.points.real %>% 
  mutate(type = "Environmentally Realistic")
#join dataframes
t1.ox.preds.j.real.agonstic <- rbind(t1.x.p.agnostic, t1.x.p.real, t1.x.e)
t1.ox.points.j.real.agonstic <- rbind(t1.x.1.p.agnostic, t1.x.1.p.real, t1.x.1.e)

#ggplot
ggplot() +
  geom_xribbon(data = t1.ox.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t1.ox.preds.j.real.agonstic, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  #geom_point(data = t1.ox.points.j.real.agonstic, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = ox.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```

##### Residuals
```{r}
# give uniq id
t1.x.e <- ox.t1.emp.preds %>% 
  mutate(type = "Empirical")
t1.x.p <-  ox.t1.preds.agnostic %>% 
  mutate(type = "Predicted")

#plot residuals
t1.x.1.e <- ox.t1.emp.points %>% 
  mutate(type = "Empirical") %>% 
  mutate(Conc.e= Conc)
t1.x.1.p <-  ox.t1.points.agnostic %>% 
  mutate(type = "Predicted")
###join dataframes
#t1.ox.preds.j <- rbind(t1.x.e, t1.x.p)
compare <- left_join(t1.x.1.e, t1.x.1.p, by = "Species") %>% 
    mutate(diff = Conc.e - Conc.y)

# Make color scale for speceis on y axis
# library(scales)
# numColors <- length(levels(compare$Group.x)) # How many colors you need
# getColors <- scales::brewer_pal(name = "Dark2") # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)
# myPalette <- getColors(n = 13)#numColors)
# names(myPalette) <- levels(compare$Group.x) # Give every color an appropriate name

#library(RColorBrewer)
#brewer.pal(n = 13, name = "Dark2")

## Plot Residuals
compare %>% 
  mutate(Species = fct_reorder(Species, diff)) %>% 
  ggplot(aes(x = -log10(abs(diff)), y = Species, color = Group.x)) +
 # geom_boxplot() +
  geom_boxplot(fill = "red", color = "black") +
  geom_point(size = 2.5) +
 # scale_x_log10() +
 # scale_x_continuous(limits = c(-7500,100)) +
  labs(title = "Residuals for Predicted NOECs"#,
     # subtitle = "Random Forest Predicted NOECs"
       ) +
  xlab("Empirical - Predicted NOEC (log10 scale)") +
  ylab("Species") +
  geom_vline(xintercept = 0, linetype = "dashed", size = 1.5, alpha = 0.4) +
 # scale_color_manual(values = rainbow(13)) +
  #scale_color_brewer()
  scale_color_futurama(name = "Taxa") +
 # coord_trans(x = "log10") +
  theme.type +
  #dark_theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)#,
#    axis.text.y = element_text(colour=rainbow(13)[compare$Group.x])
    )


#t1.ox.points.j <- rbind(t1.x.1.e, t1.x.1.p)
```

#####Compare summary statistics
```{r}
compare %>% 
  group_by(type.y) %>% 
  summarize(species = n(),
            taxa = n_distinct(Group.x),
            min = min(Conc.e),
            median = median(Conc.e),
            max = max(Conc.e))
```

### Tier 3/4
#### Predicted (agnostic)
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
ox.3 <- composition_agnostic %>% 
  mutate(translocatable = "translocatable") %>% 
  filter(
         lvl1_f %in% c("Fitness"),
         bio.org %in% c("organism", "population"), #special for tier 3/4
         #environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable")) %>%  # 1- 83 um) %>%
  left_join(groups)
  
# predict NOEC
ox.3$particles.mL.ox.stress_log10 <- predict(classif_rf_oxidative.stress, ox.3, type = "raw")

#Data collapse %>% 
ox3.summary <- ox.3 %>%
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
   mutate(particles.mL.ox.stress = (10 ^ particles.mL.ox.stress_log10) / (af.time * af.noec)) %>% 
  summarise(dose_new = quantile(particles.mL.ox.stress, 0.50))

## SSD build
ox.t3.ssd <- SSD_function_t1(filtered.data = ox3.summary, hcxlcl = 5)

#extract data frames from object
ox.t3.preds.agnostic <- as.data.frame(ox.t3.ssd[1])
ox.t3.points.agnostic <- as.data.frame(ox.t3.ssd[2])

#ggplot
ggplot(ox.t3.preds.agnostic, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t3.points.agnostic,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t3.points.agnostic, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```
#### Predicted (Realistic)
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
ox.3.real <- composition_realistic %>% 
  mutate(translocatable = "translocatable") %>% 
   filter(
         lvl1_f %in% c("Fitness"),
         bio.org %in% c("organism", "population"), #special for tier 3/4
         #environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable", "non-translocatable")) %>%  # 1- 83 um) %>%
  left_join(groups)
  
# predict NOEC
ox.3.real$particles.mL.ox.stress_log10 <- predict(classif_rf_oxidative.stress, ox.3.real, type = "raw")

#Data collapse %>% 
ox3.real.summary <- ox.3.real %>%
  mutate(particles.mL.ox.stress_log10 = 10^particles.mL.ox.stress_log10) %>% 
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(particles.mL.ox.stress_log10, 0.50))

## SSD build
ox.t3.real.ssd <- SSD_function_t1(filtered.data = ox3.real.summary, hcxlcl = 5)

#extract data frames from object
ox.t3.preds.real <- as.data.frame(ox.t3.real.ssd[1])
ox.t3.points.real <- as.data.frame(ox.t3.real.ssd[2])

#ggplot
ggplot(ox.t3.preds.real, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t3.points.real,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t3.points.real, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

#### Empirical
```{r}
#Filter empirical data
ox.3.emp <- aoc_final %>% 
  filter(#environment == "Marine",
         translocatable == "translocatable",
         bio.org %in% c("organism", "population"),
         lvl1_f %in% c("Fitness")) %>%  
  mutate(dose_new = particles.mL.ox.stress / (af.time * af.noec)) %>%  
    drop_na(dose_new) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(dose_new, 0.50)) #convert from log10  
  
## SSD build
ox.t3.ssd <- SSD_function_t1(filtered.data = ox.3.emp, hcxlcl = 5)

#extract data frames from object
ox.t3.emp.preds <- as.data.frame(ox.t3.ssd[1])
ox.t3.emp.points <- as.data.frame(ox.t3.ssd[2])

#ggplot
ggplot(ox.t3.emp.preds, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = ox.t3.emp.points,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = ox.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

##### Comparison of Realistic, empirical, and Agnostic SSDs
```{r}
# give uniq id
t3.x.p.agnostic <-  ox.t3.preds.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic")
t3.x.p.real <-  ox.t3.preds.real %>% 
  mutate(type = "Environmentally Realistic")
t3.x.1.p.agnostic <- ox.t3.points.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic") 
t3.x.1.p.real <-  ox.t3.points.real %>% 
  mutate(type = "Environmentally Realistic")
t3.x.e <- ox.t3.emp.preds %>% 
  mutate(type = "Empirical") 
t3.x.1.e <- ox.t3.emp.points %>% 
  mutate(type = "Empirical") 

#join dataframes
t3.ox.preds.j.real.agonstic <- rbind(t3.x.p.agnostic, t3.x.p.real, t3.x.e)
t3.ox.points.j.real.agonstic <- rbind(t3.x.1.p.agnostic, t3.x.1.p.real, t3.x.1.e)

#ggplot
ggplot() +
  geom_xribbon(data = t3.ox.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t3.ox.preds.j.real.agonstic, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  #geom_point(data = t3.ox.points.j.real.agonstic, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = ox.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 3/4, 1 - 83 m; ERM = Surface Area") +
  coord_trans(x = "log10") +
  scale_x_continuous(name = "Particles/mL (1 - 5,000 m)",
                       breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```

Sample plot but displaying all points and only showing empirical vs. agnostic to demonstrate more data points on predicted.

```{r}
t3.compare.preds <- t3.ox.preds.j.real.agonstic %>% filter(type != "Environmentally Realistic")
t3.compare.points <- t3.ox.points.j.real.agonstic %>% filter(type != "Environmentally Realistic")

#ggplot
ggplot() +
  # geom_xribbon(data = t3.ox.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t3.compare.preds, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  geom_point(data = t3.compare.points, aes(x = Conc, y =frac, color = type), alpha = 0.7) + 
  #geom_text_repel(data = ox.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - variable (mouth size) m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```
#####Compare summary statistics
```{r}
t3.compare.points %>% 
  group_by(type) %>% 
  summarize(species = n(),
            taxa = n_distinct(Group),
            min = min(Conc),
            median = median(Conc),
            max = max(Conc))
```

Relative Uncertainty of Tier 3 ox Dilution SSDs (mean(predicted / standard error))
```{r}
t3.ox.preds.j.real.agonstic %>% 
  group_by(type) %>% 
  summarize(relative.uncertainty = mean(se / est))
```
```{r}
t3.ox.preds.j.real.agonstic %>% 
  group_by(type) %>% 
  summarize(HC5 = est[5],
            se = se[5]) 
```



For comparison, the surface area particles/L for tiers 1-4 are:
tier 1: 236 (hc5 lower 95% CI; tissue and above, 1st quantile)
tier 2: 1,312 (hc5; tissue and above, 1st quantile)
tier 3: 3,097 (hc5; organism and above, median)
tier 4: 14,397 (hc10; organism and above, median)

```{r}
ox.t1.preds.agnostic$lcl[5]
ox.t1.preds.agnostic$est[5]
ox.t3.preds.real$est[5]
ox.t3.preds.real$est[10]
```



## Food Dilution
#### Polymer/Shape Agnostic
Translocatable is included below.
```{r}
#define base parameters for all SSDs
composition_agnostic_food <- df_oxidative.stress %>% 
  # make entry for each species
  distinct(species_f, max.size.ingest.mm, life.stage, bio.org, lvl1_f, lvl2_f, 
           #lvl3_f, 
           exposure.duration.d, organism.group, effect.metric, acute.chronic_f, environment, 
           exposure.route, 
           effect.score,
           translocatable,
           # make synonymous with training data for true comparison
          EVA_frac,
          #LTX_frac,
          PA_frac, PC_frac, PE_frac, PET_frac, PLA_frac, PMMA_frac, PP_frac, PS_frac, PUR_frac, PVC_frac, fiber_frac,       fragment_frac, sphere_frac
           ) %>% 
  #give summary statistics for typical composition of 1-5,000 um particle distribution in aquatic environment
  mutate(
  #       EVA_frac = 0.06,
  #       LTX_frac = 0,
  #       PA_frac = 0.12,
  #       PC_frac = 0,
  #       PE_frac = 0.25,
  #       PET_frac = 0.165,
  #       PLA_frac = 0,
  #       PMMA_frac = 0,
  #       PP_frac = 0.145,
  #       PS_frac = 0.085,
  #       PUR_frac = 0,
  #       PVC_frac = 0.02,
  #       fiber_frac = 0.485 * 1.1627, #correction factor to get to 100% because training data doesn't have film
  #       fragment_frac = 0.31 * 1.1627,
  #       sphere_frac = 0.065 * 1.1627,
  #effect = "N",
  #common metrics for all SSDs
  #lvl1_f = "Fitness",
 # life.stage = "Adult",
 # exposure.route = "water",
 # environment = "Marine",
  #acute.chronic_f = "Chronic",
  #effect.metric = "NOEC"
  ) %>% 
  mutate(af.time = case_when(acute.chronic_f == "Chronic" ~ 1,
                             acute.chronic_f == "Acute" ~ 10)) %>% 
  mutate(af.noec = case_when(effect.metric == "HONEC" ~ 1,
                             effect.metric == "LOEC" ~ 2,
                             effect.metric == "NOEC" ~ 1,
                             effect.metric == "EC10" ~ 1,
                             effect.metric == "EC50" ~ 10,
                             effect.metric == "LC50" ~ 10,
                             #effect.metric == "not_available" ~ 1
                             )) %>% 

  drop_na()
```

#### Realistic Polymers and Shapes in Environment
Abundance of most commonly found polymers based on Table S3 of kooi and Kolemans 2019. Shape abundance based on the main text of Kooi and Koelmans 2019. Since there are no training data for films (5.5% in envirnoment) or foam (3.5% in environment), they were omitted from this synthetic dataset and all other categories were increased by a factor of 1.16 to reach 100%. https://pubs.acs.org/doi/suppl/10.1021/acs.estlett.9b00379/suppl_file/ez9b00379_si_001.pdf
```{r}
#define base parameters for all SSDs
composition_realistic_food <- df_oxidative.stress %>% 
  # make entry for each species
  distinct(species_f, max.size.ingest.mm, life.stage, bio.org, lvl1_f, lvl2_f,
           effect.score,
           #lvl3_f, 
           exposure.duration.d, 
           organism.group,
           effect.metric,
           acute.chronic_f, environment,  exposure.route, 
           translocatable,
           # make synonymous with training data for true comparison
          # EVA_frac, LTX_frac, PA_frac, PC_frac, PE_frac, PET_frac, PLA_frac, PMMA_frac, PP_frac, PS_frac, PUR_frac, PVC_frac, fiber_frac,       fragment_frac, sphere_frac
           ) %>% 
  #give summary statistics for typical composition of 1-5,000 um particle distribution in aquatic environment
  mutate(
        EVA_frac = 0.06,
        #LTX_frac = 0,
        PA_frac = 0.12,
        PC_frac = 0,
        PE_frac = 0.25,
        PET_frac = 0.165,
        PLA_frac = 0,
        PMMA_frac = 0,
        PP_frac = 0.145,
        PS_frac = 0.085,
        PUR_frac = 0,
        PVC_frac = 0.02,
        fiber_frac = 0.485 * 1.1627, #correction factor to get to 100% because training data doesn't have film
        fragment_frac = 0.31 * 1.1627,
        sphere_frac = 0.065 * 1.1627,
  #effect = "N",
  #common metrics for all SSDs
  #exposure.route = "water",
  #make distinct above instead of forcing here
  #environment = "Marine",
  #acute.chronic_f = "Chronic",
 # effect.metric = "NOEC"
  ) %>% 
  mutate(af.time = case_when(acute.chronic_f == "Chronic" ~ 1,
                             acute.chronic_f == "Acute" ~ 10)) %>% 
  mutate(af.noec = case_when(effect.metric == "HONEC" ~ 1,
                             effect.metric == "LOEC" ~ 2,
                             effect.metric == "NOEC" ~ 1,
                             effect.metric == "EC10" ~ 1,
                             effect.metric == "EC50" ~ 10,
                             effect.metric == "LC50" ~ 10,
                             #effect.metric == "not_available" ~ 1
                             )) %>% 
  drop_na()

skim(composition_realistic_food)
```
### Tier 1

```{r}
#assign groups
food.1 <- composition_agnostic_food %>% 
   filter(organism.group != "Algae", #all food dilution
         lvl1_f %in% c("Fitness"),
         ##environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable", "non-translocatable")) %>%  # 1- 83 um) %>%
  left_join(groups)
  
# predict NOEC
food.1$particles.mL.food.dilution_log10 <- predict(classif_rf_food.dilution, food.1, type = "raw") 

#Data collapse
food1.summary <- food.1 %>%
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
  mutate(particles.mL.food.dilution = (10 ^ particles.mL.food.dilution_log10) / (af.time * af.noec)) %>% 
  summarise(dose_new = quantile(particles.mL.food.dilution, 0.50)) 

## SSD build
food.t1.ssd <- SSD_function_t1(filtered.data = food1.summary, hcxlcl = 5)

#extract data frames from object
food.t1.preds.agnostic <- as.data.frame(food.t1.ssd[1])
food.t1.points.agnostic <- as.data.frame(food.t1.ssd[2])

#ggplot
ggplot(food.t1.preds.agnostic, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t1.points.agnostic,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t1.points.agnostic, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 5,000 m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme

```

####Comparison to empirical
##### Empirical alone
```{r}
food.1.emp <- aoc_final %>%
  filter(Group != "Algae") %>% 
  filter(lvl1_f == "Fitness",
        # #environment == "Marine",
         between(size.length.um.used.for.conversions, 1, 5000)) %>% 
         mutate(dose_new = particles.mL.food.dilution / (af.time * af.noec)) %>%  
         drop_na(dose_new) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(dose_new, 0.50))

## SSD build
food.t1.emp.ssd <- SSD_function_t1(filtered.data = food.1.emp, hcxlcl = 5)

#extract data frames from object
food.t1.emp.preds <- as.data.frame(food.t1.emp.ssd[1])
food.t1.emp.points <- as.data.frame(food.t1.emp.ssd[2])

#ggplot
ggplot(food.t1.emp.preds, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t1.emp.points,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution (Polymer and Shape Agnostic)",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```
##### Overlay
```{r}
# give uniq id
t1.x.e <- food.t1.emp.preds %>% 
  mutate(type = "Empirical")
t1.x.p.agnostic <-  food.t1.preds.agnostic %>% 
  mutate(type = "Predicted")
t1.x.1.e <- food.t1.emp.points %>% 
  mutate(type = "Empirical") 
t1.x.1.p.agnostic <-  food.t1.points.agnostic %>% 
  mutate(type = "Predicted")

#join dataframes
t1.food.preds.j <- rbind(t1.x.e, t1.x.p.agnostic)
t1.food.points.j <- rbind(t1.x.1.e, t1.x.1.p.agnostic)

#ggplot
ggplot() +#, aes_string(x = "est")) +
  geom_xribbon(data = t1.food.preds.j, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.4) +
  geom_line(data = t1.food.preds.j, aes_string(x = "est", y = "percent/100", fill = "type")) +
  geom_point(data = t1.food.points.j, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = food.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution (Polymer and Shape Agnostic)",
       subtitle = "Tier 1/2, 1 - 5,000 m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type #user theme
```
#### Realistic Environmental Polymers and Shapes
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
food.1.real <- composition_realistic_food %>% 
   filter(organism.group != "Algae", #all food dilution
         lvl1_f %in% c("Fitness"),
         bio.org %in% c("organism", "population"), #special for tier 3/4
         #environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable", "non-translocatable")) %>%  # 1- 83 um) %>%
  left_join(groups)
  
# predict NOEC
food.1.real$particles.mL.food.dilution_log10 <- predict(classif_rf_food.dilution, food.1.real, type = "raw")

#Data collapse
food1.summary.real <- food.1.real %>%
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
   mutate(particles.mL.food.dilution = (10 ^ particles.mL.food.dilution_log10) / (af.time * af.noec)) %>% 
  summarise(dose_new = quantile(particles.mL.food.dilution, 0.50)) #convert from log10

## SSD build
food.t1.ssd.real <- SSD_function_t1(filtered.data = food1.summary.real, hcxlcl = 5)

#extract data frames from object
food.t1.preds.real <- as.data.frame(food.t1.ssd.real[1])
food.t1.points.real <- as.data.frame(food.t1.ssd.real[2])

#ggplot
ggplot(food.t1.preds.real, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t1.points.real,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t1.points.real, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution (Realistic Shapes and Polymers)",
       subtitle = "Tier 1/2, 1 - variable (mouth size) m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

##### Comparison of Realistic, empirical, and Agnostic SSDs
```{r}
# give uniq id
t1.x.p.agnostic <-  food.t1.preds.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic")
t1.x.p.real <-  food.t1.preds.real %>% 
  mutate(type = "Environmentally Realistic")
t1.x.1.p.agnostic <- food.t1.points.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic") 
t1.x.1.p.real <-  food.t1.points.real %>% 
  mutate(type = "Environmentally Realistic")
#join dataframes
t1.food.preds.j.real.agonstic <- rbind(t1.x.p.agnostic, t1.x.p.real, t1.x.e)
t1.food.points.j.real.agonstic <- rbind(t1.x.1.p.agnostic, t1.x.1.p.real, t1.x.1.e)

#ggplot
ggplot() +
  geom_xribbon(data = t1.food.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t1.food.preds.j.real.agonstic, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  #geom_point(data = t1.food.points.j.real.agonstic, aes(x = Conc, y =frac, color = type), alpha = 0.2) + 
  #geom_text_repel(data = food.t1.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - variable (mouth size) m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```
### Tier 3/4
#### Predicted (agnostic)
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
food.3 <- composition_agnostic_food %>% 
  filter(organism.group != "Algae", #all food dilution
         lvl1_f %in% c("Fitness"),
         bio.org %in% c("organism", "population"), #special for tier 3/4
         #environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable", "non-translocatable")) %>%  # 1- 83 um) %>%
  left_join(groups)
  
# predict NOEC
food.3$particles.mL.food.dilution_log10 <- predict(classif_xgbTree_food.dilution, food.3, type = "raw")

#Data collapse %>% 
food3.summary <- food.3 %>%
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
   mutate(particles.mL.food.dilution = (10 ^ particles.mL.food.dilution_log10) / (af.time * af.noec)) %>% 
  summarise(dose_new = quantile(particles.mL.food.dilution, 0.50))

## SSD build
food.t3.ssd <- SSD_function_t1(filtered.data = food3.summary, hcxlcl = 5)

#extract data frames from object
food.t3.preds.agnostic <- as.data.frame(food.t3.ssd[1])
food.t3.points.agnostic <- as.data.frame(food.t3.ssd[2])

#ggplot
ggplot(food.t3.preds.agnostic, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t3.points.agnostic,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t3.points.agnostic, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```
#### Predicted (Realistic)
```{r}
#Get organism group for each species
groups <- aoc_z %>% 
  distinct(species_f, Group)

#assign groups
food.3.real <- composition_realistic_food %>% 
   filter(organism.group != "Algae", #all food dilution
         lvl1_f %in% c("Fitness"),
         bio.org %in% c("organism", "population"), #special for tier 3/4
         #environment == "Marine",
         exposure.route == "water",
         translocatable %in% c("translocatable", "non-translocatable")) %>%  
  left_join(groups)
  
# predict NOEC
food.3.real$particles.mL.food.dilution_log10 <- predict(classif_xgbTree_food.dilution, food.3.real, type = "raw")

#Data collapse %>% 
food3.real.summary <- food.3.real %>%
  mutate(particles.mL.food.dilution = 10^particles.mL.food.dilution_log10) %>% 
    rename(Species = species_f) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(particles.mL.food.dilution, 0.50))

## SSD build
food.t3.real.ssd <- SSD_function_t1(filtered.data = food3.real.summary, hcxlcl = 5)

#extract data frames from object
food.t3.preds.real <- as.data.frame(food.t3.real.ssd[1])
food.t3.points.real <- as.data.frame(food.t3.real.ssd[2])

#ggplot
ggplot(food.t3.preds.real, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t3.points.real,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t3.points.real, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

#### Empirical
```{r}
#Filter empirical data
food.3.emp <- aoc_final %>% 
  filter(organism.group != "Algae") %>%
  filter(#environment == "Marine",
         between(size.length.um.used.for.conversions, 1, 5000),
         bio.org %in% c("organism", "population"),
         lvl1_f %in% c("Fitness")) %>%  
  mutate(dose_new = particles.mL.food.dilution / (af.time * af.noec)) %>%  
    drop_na(dose_new) %>% 
  group_by(Species, Group) %>% 
  summarise(dose_new = quantile(dose_new, 0.50)) #convert from log10  
  
## SSD build
food.t3.ssd <- SSD_function_t1(filtered.data = food.3.emp, hcxlcl = 5)

#extract data frames from object
food.t3.emp.preds <- as.data.frame(food.t3.ssd[1])
food.t3.emp.points <- as.data.frame(food.t3.ssd[2])

#ggplot
ggplot(food.t3.emp.preds, aes_string(x = "est")) +
  geom_xribbon(aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100"), alpha = 0.2, color = "blue", fill = "lightblue") +
  geom_line(aes_string(y = "percent/100"), color = "gray") +
  geom_point(data = food.t3.emp.points,aes(x = Conc, y =frac, color = Group)) + 
  geom_text_repel(data = food.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Model-Predicted Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - 83 m; ERM = Surface Area ",
       x = "particles/L (aligned to 1-5,000 um; translocation limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
    fill.type + #user-selected
  color.type + #user-selected
  theme.type #user theme
```

##### Comparison of Realistic, empirical, and Agnostic SSDs
```{r}
# give uniq id
t3.x.p.agnostic <-  food.t3.preds.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic")
t3.x.p.real <-  food.t3.preds.real %>% 
  mutate(type = "Environmentally Realistic")
t3.x.1.p.agnostic <- food.t3.points.agnostic %>% 
  mutate(type = "Polymer and Shape Agnostic") 
t3.x.1.p.real <-  food.t3.points.real %>% 
  mutate(type = "Environmentally Realistic")
t3.x.e <- food.t3.emp.preds %>% 
  mutate(type = "Empirical") 
t3.x.1.e <- food.t3.emp.points %>% 
  mutate(type = "Empirical") 

#join dataframes
t3.food.preds.j.real.agonstic <- rbind(t3.x.p.agnostic, t3.x.p.real, t3.x.e)
t3.food.points.j.real.agonstic <- rbind(t3.x.1.p.agnostic, t3.x.1.p.real, t3.x.1.e)

#ggplot
ggplot() +
  geom_xribbon(data = t3.food.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t3.food.preds.j.real.agonstic, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  #geom_point(data = t3.food.points.j.real.agonstic, aes(x = Conc, y =frac, color = Group), alpha = 0.7) + 
  #geom_text_repel(data = food.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - variable (mouth size) m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```

Sample plot but displaying all points and only showing empirical vs. agnostic to demonstrate more data points on predicted.

```{r}
t3.compare.preds <- t3.food.preds.j.real.agonstic %>% filter(type != "Environmentally Realistic")
t3.compare.points <- t3.food.points.j.real.agonstic %>% filter(type != "Environmentally Realistic")

#ggplot
ggplot() +
  # geom_xribbon(data = t3.food.preds.j.real.agonstic, aes_string(xmin = "lcl", xmax = "ucl", y = "percent/100", fill = "type"), alpha = 0.3) +
  geom_line(data = t3.compare.preds, aes_string(x = "est", y = "percent/100", fill = "type", color = "type")) +
  geom_point(data = t3.compare.points, aes(x = Conc, y =frac, color = type), alpha = 0.7) + 
  #geom_text_repel(data = food.t3.emp.points, aes(x = Conc, y = frac, label = Species, color = Group), nudge_x = 0.2, size = 3, segment.alpha = 0.5) + 
  scale_y_continuous("Species Affected (%)", labels = scales::percent, limits = c(0,1)) +
  labs(title = "Predicted vs. Empirical Microplastics Species Sensitivity Distribution",
       subtitle = "Tier 1/2, 1 - variable (mouth size) m; ERM = Volume",
       x = "particles/L (aligned to 1-5,000 um; ingestion limited)") +
  coord_trans(x = "log10") +
  scale_x_continuous(breaks = scales::trans_breaks("log10", function(x) 10^x, n = 15),
                     labels = trans_format("log10", scales::math_format(10^.x))) + 
  #scale_fill_manual(name = "SSD Data") +
  #fill.type + #user-selected
  #color.type + #user-selected
  theme.type + #user theme
  theme(legend.position = "top")
```
#####Compare summary statistics
```{r}
t3.compare.points %>% 
  group_by(type) %>% 
  summarize(species = n(),
            taxa = n_distinct(Group),
            min = min(Conc),
            median = median(Conc),
            max = max(Conc))
```

Relative Uncertainty of Tier 3 Food Dilution SSDs (mean(predicted / standard error))
```{r}
t3.food.preds.j.real.agonstic %>% 
  group_by(type) %>% 
  summarize(relative.uncertainty = mean(se / est))
```
```{r}
t3.food.preds.j.real.agonstic %>% 
  group_by(type) %>% 
  summarize(HC5 = est[5],
            se = se[5]) 
```


## HCxx Metrics
For comparison, the volume particles/L for tiers 1-4 are:
tier 1: 3 (hc5 lower 95% CI; tissue and above, 1st quantile)
tier 2: 21 (hc5; tissue and above, 1st quantile)
tier 3: 17 (hc5; organism and above, median)
tier 4: 105 (hc10; organism and above, median)

```{r}
hcxx_food <- tibble(
 "Tier" = c('Tier1', 'Tier2', 'Tier3', 'Tier4'),
"Empirical" = c(food.t1.emp.preds$lcl[5],  food.t1.emp.preds$est[5],  food.t3.emp.preds$est[5],  food.t3.emp.preds$est[10]),
"Predicted" = c(
food.t1.preds.agnostic$lcl[5],
food.t1.preds.agnostic$est[5],
food.t3.preds.agnostic$est[5],
food.t3.preds.agnostic$est[10]),
"Environmentally Realistic Polymer/Shape Predicted" = c(
  food.t1.preds.real$lcl[5],
  food.t1.preds.real$est[5],
  food.t3.preds.real$est[5],
  food.t3.preds.real$est[10])
) %>% 
  mutate(Empirical = Empirical * 1000,
         Predicted = Predicted * 1000,
         `Environmentally Realistic Polymer/Shape Predicted` = `Environmentally Realistic Polymer/Shape Predicted` * 1000)

kable(hcxx_food, caption = "Food Dilution Thresholds")

write.csv(hcxx_food, file = "Simulated Distributions/BigDataManuscript/foodDilutionhcxx.csv")
```
```{r}
hcxx_ox <- tibble(
 "Tier" = c('Tier1', 'Tier2', 'Tier3', 'Tier4'),
"Empirical" = c(ox.t1.emp.preds$lcl[5],  ox.t1.emp.preds$est[5],  ox.t3.emp.preds$est[5],  ox.t3.emp.preds$est[10]),
"Predicted" = c(
ox.t1.preds.agnostic$lcl[5],
ox.t1.preds.agnostic$est[5],
ox.t3.preds.agnostic$est[5],
ox.t3.preds.agnostic$est[10]),
"Environmentally Realistic Polymer/Shape Predicted" = c(
  ox.t1.preds.real$lcl[5],
  ox.t1.preds.real$est[5],
  ox.t3.preds.real$est[5],
  ox.t3.preds.real$est[10])
) %>% 
  mutate(Empirical = Empirical * 1000,
         Predicted = Predicted * 1000,
         `Environmentally Realistic Polymer/Shape Predicted` = `Environmentally Realistic Polymer/Shape Predicted` * 1000)

kable(hcxx_ox, caption = "ox Dilution Thresholds")

write.csv(hcxx_ox, file = "Simulated Distributions/BigDataManuscript/oxDilutionhcxx.csv")
```



```{r eval=FALSE, include=FALSE}
org_endpoint_comb <- aoc_z %>%
  dplyr::select(organism.group, bio.org, lvl1_f) %>%
  distinct() 
df_expand <- org_endpoint_comb %>%
  expand_grid(unif_df)

#Ran the code below too to see if the glm methods were the same. They are returning the same response. 
df_expand$prob <- predict(final_model, df_expand, type = "response")
for(row in 1:nrow(org_endpoint_comb)){
  slice <- org_endpoint_comb[row,]
  doses <- inner_join(df_expand, slice) %>%
    dplyr::select(-organism.group, -bio.org, -lvl1_f) %>%
    pivot_longer(cols = -prob, names_to = "type", values_to = "values")
 plot <- ggplot(doses) + geom_point(aes(x = values, y = prob)) + facet_wrap(type~., scales = "free") + labs(title = paste0(as.character(unlist(slice)), collapse = "_"))
  ggsave(plot = plot, filename = paste0(paste0(as.character(unlist(slice)), collapse = "_"), ".png"), path = "Tox Data/figures")
}  
#Testing this out for actual data, not extrapolated uniform data using the training dataset.
org_endpoint_comb <- actual_model_data %>%
  dplyr::select_if(function(col) is.character(col) | 
                                   is.factor(col)) %>%
  distinct() 
df_expand <- actual_model_data 
for(row in 1:nrow(org_endpoint_comb)){
  slice <- org_endpoint_comb[row,]
  doses <- inner_join(df_expand, slice) %>%
    dplyr::select_if(is.numeric) %>%
    pivot_longer(cols = -.outcome, names_to = "type", values_to = "values")
 plot <- ggplot(doses) + geom_point(aes(x = values, y = .outcome)) + facet_wrap(type~., scales = "free") + labs(title = paste0(as.character(unlist(slice)), collapse = "_"))
  ggsave(plot = plot, filename = paste0(paste0(as.character(unlist(slice)), collapse = "_"), ".png"), path = "Tox Data/figures")
}  
```

# SSD

```{r eval=FALSE, include=FALSE}
df_expand_sensitivity_distribution <- df_expand %>%
  filter(prob > 0.5) %>%
  group_by(organism.group, bio.org, lvl1_f) %>% #Can add other factors here if we want to flesh this out for each organism.
  summarise(dose.um3.mL.master = min(dose.um3.mL.master), dose.surface.area.um2.mL.master = min(dose.surface.area.um2.mL.master)) %>%
  ungroup()
ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.surface.area.um2.mL.master))
ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.um3.mL.master))
#Other Option with automated extraction from the dataset. 
df_expand_sensitivity_distribution <- df_expand %>%
  filter(.outcome > 0.5) %>%
  group_by_if(function(col) is.character(col) | 
                                   is.factor(col)) %>% #Can add other factors here if we want to flesh this out for each organism.
  summarise_if(is.numeric, min) %>%
  ungroup()
ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.particles.mL.master))
```

#Run Merels distribution through the model to predict the liklihood of risk in the environment for organism endpoint combinations. 


# Sensitivity Analysis
it would be great to use the full approach to find out which model parameters and MP subclasses the HC5 is most sensitive to.And also if that HC5 is sensitive to which of Merels compartment-specific MP parameterisations is used.

# Shiny App Tabs
1) ML predictor
2) Chemical data
  Bioaccumulation model, partitioning with chemicals/particles. Would add toxicity from chemicals to toxicity from particles! Use same model from Worm paper. Would show how it would compare with toxicities from particles. We have criticial body burden concept (lipids) 
 2021 GitHub, Inc.