---
title: "Simulated Probabilistic Distributions"
author: "Scott Coffin"
date: "2/24/2021"
output:   
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
    includes:
     # after_body: footer.html
  word_document:
    toc: yes
---


#Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

```{r library}
# Bimodal universal shape distribution for environmental microplastic from Kooi and Koelmans (2019)
library(truncnorm)
library(tidyverse)
library(MonteCarlo)# Monte Carlo Simulation 
library(gridExtra)
library(msm) ## rtnorm - get upper and lower limit of shape distribution
library(GeneralizedHyperbolic) ## normal-inverse Gaussian
library(skimr)
library(drc) #dose-response curves
library(readr)
library(readxl)
library(MASS)
library(caret)
library(DALEX)
library(ggdark)
```

#The idea here is we want to be able to just change the dataset and model here and then the entire code base will react to the update. The challenge is that making the right synthetic and uniform datasets will differ depending on the column types. Is it safe to assume that there will be no numeric variables in the model besides the concentrations which will be present in the development of the synthetic and uniform datasets?  
```{r}
# load tox data (cleaned for only what need to go into the model) and model

#final_model <- readRDS("final_rf_model.rds")

aoc_z <- readRDS(file = "Tox Data/aoc_z.Rda")

```

# Model Build
## Particle Characteristics
This model's purpose is to predict toxicity for a synthetic dataset, so it should be trained on particle-specific characteristics and a SINLGE dose metric (particle count).
```{r}
df <- aoc_z %>% 
filter(tech.tier.zero == "Pass") %>% #gives studies that pass technical quality criteria
  #filter(risk.tier.zero == "Pass") %>%  #only studies applicable for risk assessment. VERY RESTRICTIVE 
  dplyr::select(c(
    ### Organism characteristics ###
    #organism.group, # very general organism group (e.g. fish, crustacea, etc.) - 13 levels
    species_f, #specific species (113 levels)
    #genus, # 96 levels
    max.size.ingest.mm,
    acute.chronic_f, #binary classification - species specific (makes HUGE difference)
    #lvl1_f, # general endpoint (e.g. fitness, behavior) (9 levels)
    lvl2_f, #specific endpoint (e.g. mortality, growth)(45 levels)
    #environment,# freshwater, marine or terrestrial (should make little difference)
    life.stage, #4 levels, 100% complete (moderately important)
    bio.org, # (organismal, tissue, population, etcl) 5 levels, 100% complete (highly important)
    exposure.route, #water, food, sediment 
    
    ## dose metrics ##
    #dose.um3.mL.master, #volume/volume dose
    #dose.mg.L.master, #mass/volume dose
    #dose.particles.mL.master, #particle/volume dose
    dose.surface.area.um2.mL.master, #area/volume dose
    #dose.specific.surface.area.um2.mg.mL, # specific surface area/volume dose
    
    ## Particle characteristics ##
    polymer, #14 levels
    shape, #4 levels
    size.length.um.used.for.conversions, #continuous, 99.5% complete
    #particle.volume.um3, #continuous, 89% complete
    #density.mg.um.3, #continous, 97% complete
    #particle.surface.area.um2, #continuous surface area
    #particle.surface.area.um2.mg, #specific surface area
    #mass.per.particle.mg, # particle mass
    
    ## Response variable
    effect, # BINARY (y/n) 100% complete
   # effect.metric #Honec, noec, loec, etc. NOTE: NA is an effect, but somewhere along the curve (unassigned magnitude)
                  )) %>% 
  filter(exposure.route == "water") %>% 
  drop_na() %>%  #drop missing
  mutate(effect_10 = case_when( #convert ordinal to numeric
      effect == "Y" ~ 1,
      effect == "N" ~ 0
    )) %>%
  mutate(effect_10 = factor(effect_10)) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::select(-c(effect, 
                   exposure.route#,
                   #effect.metric
                   )) #%>%
  #mutate(sa_vol_ratio = dose.surface.area.um2.mL.master/dose.um3.mL.master)
```

```{r}
response <- as.numeric(as.character(df$effect_10))
predictors <- as.data.frame(df %>% dplyr::select(-effect_10))
#build glm
glm_model <- train(effect_10~., data = df, method = "glm", family = "binomial")
#build explainer for easy interpretation
explainer_glm_model <- DALEX::explain(glm_model, label = "glm", data = predictors, y = response)

#classifier plot
classif_glm <- model_parts(explainer_glm_model, loss_function = loss_root_mean_square)
#plot classifier
#plot(classif_glm)
```

```{r}
#partial dependence plot by dose
pdp_classif_glm  <- model_profile(explainer_glm_model, variable = "dose.particles.mL.master", type = "partial")
#partial dependence plot by particle surface area
pdp_classif_glm_SA  <- model_profile(explainer_glm_model, variable = "particle.surface.area.um2", type = "partial")
#partial dependence plot by particle length
pdp_classif_glm_length  <- model_profile(explainer_glm_model, variable = "size.length.um.used.for.conversions", type = "partial")
#partial dependence plot by polymer
pdp_classif_glm_polymer  <- model_profile(explainer_glm_model, variable = "polymer", type = "partial")

plot(pdp_classif_glm,  pdp_classif_glm_SA,  pdp_classif_glm_length)

plot(pdp_classif_glm_polymer)
```
## Dose Metrics

```{r}
df2 <- aoc_z %>% 
filter(tech.tier.zero == "Pass") %>% #gives studies that pass technical quality criteria
  #filter(risk.tier.zero == "Pass") %>%  #only studies applicable for risk assessment. VERY RESTRICTIVE 
  dplyr::select(c(
    ### Organism characteristics ###
    #organism.group, # very general organism group (e.g. fish, crustacea, etc.) - 13 levels
    species_f, #specific species (113 levels)
    #genus, # 96 levels
    max.size.ingest.mm,
    acute.chronic_f, #binary classification - species specific (makes HUGE difference)
    #lvl1_f, # general endpoint (e.g. fitness, behavior) (9 levels)
    lvl2_f, #specific endpoint (e.g. mortality, growth)(45 levels)
    #environment,# freshwater, marine or terrestrial (should make little difference)
    #life.stage, #4 levels, 100% complete (moderately important)
    bio.org, # (organismal, tissue, population, etcl) 5 levels, 100% complete (highly important)
    exposure.route, #water, food, sediment 
    
    ## dose metrics ##
    dose.um3.mL.master, #volume/volume dose
    dose.mg.L.master, #mass/volume dose
    dose.particles.mL.master, #particle/volume dose
    dose.surface.area.um2.mL.master, #area/volume dose
   # dose.specific.surface.area.um2.mg.mL, # specific surface area/volume dose
    
    ## Particle characteristics ##
    polymer, #14 levels
    shape, #4 levels
    #size.length.um.used.for.conversions, #continuous, 99.5% complete
    #particle.volume.um3, #continuous, 89% complete
    #density.mg.um.3, #continous, 97% complete
    #particle.surface.area.um2, #continuous surface area
    #particle.surface.area.um2.mg, #specific surface area
    #mass.per.particle.mg, # particle mass
    
    ## Response variable
    effect, # BINARY (y/n) 100% complete
   # effect.metric #Honec, noec, loec, etc. NOTE: NA is an effect, but somewhere along the curve (unassigned magnitude)
                  )) %>% 
  filter(exposure.route == "water") %>% 
  drop_na() %>%  #drop missing
  mutate(effect_10 = case_when( #convert ordinal to numeric
      effect == "Y" ~ 1,
      effect == "N" ~ 0
    )) %>%
  mutate(effect_10 = factor(effect_10)) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::select(-c(effect, 
                   exposure.route#,
                   #effect.metric
                   )) #%>%
  #mutate(sa_vol_ratio = dose.surface.area.um2.mL.master/dose.um3.mL.master)
```

```{r}
response2 <- as.numeric(as.character(df2$effect_10))
predictors2 <- as.data.frame(df2 %>% dplyr::select(-effect_10))
#build glm
glm_model2 <- train(effect_10~., data = df2, method = "glm", family = "binomial")
#build explainer for easy interpretation
explainer_glm_model2 <- DALEX::explain(glm_model2, label = "glm", data = predictors2, y = response2)

#classifier plot
classif_glm2 <- model_parts(explainer_glm_model2, loss_function = loss_root_mean_square)
#plot classifier
#plot(classif_glm2)
```

```{r}
#partial dependence plot by dose metrics
pdp_classif_glm_p  <- model_profile(explainer_glm_model2, variable = "dose.particles.mL.master", type = "partial")
pdp_classif_glm_v  <- model_profile(explainer_glm_model2, variable = "dose.um3.mL.master", type = "partial")
pdp_classif_glm_m  <- model_profile(explainer_glm_model2, variable = "dose.mg.L.master", type = "partial")
pdp_classif_glm_SA  <- model_profile(explainer_glm_model2, variable = "dose.surface.area.um2.mL.master", type = "partial")
#pdp_classif_glm_SSA  <- model_profile(explainer_glm_model2, variable = "dose.specific.surface.area.um2.mg.mL", type = "partial")

#partial dependence plot by polymer

plot(pdp_classif_glm_p,  pdp_classif_glm_v,  pdp_classif_glm_m, pdp_classif_glm_SA)#, pdp_classif_glm_SSA)
```

## Polymer Type
This model's purpose is to predict toxicity for a synthetic dataset, so it should be trained on particle-specific characteristics and a SINLGE dose metric (particle count).
```{r}
df <- aoc_z %>% 
filter(tech.tier.zero == "Pass") %>% #gives studies that pass technical quality criteria
  #filter(risk.tier.zero == "Pass") %>%  #only studies applicable for risk assessment. VERY RESTRICTIVE 
  dplyr::select(c(
    ### Organism characteristics ###
    #organism.group, # very general organism group (e.g. fish, crustacea, etc.) - 13 levels
    species_f, #specific species (113 levels)
    #genus, # 96 levels
    max.size.ingest.mm,
    acute.chronic_f, #binary classification - species specific (makes HUGE difference)
    #lvl1_f, # general endpoint (e.g. fitness, behavior) (9 levels)
    lvl2_f, #specific endpoint (e.g. mortality, growth)(45 levels)
    #environment,# freshwater, marine or terrestrial (should make little difference)
    #life.stage, #4 levels, 100% complete (moderately important)
    bio.org, # (organismal, tissue, population, etcl) 5 levels, 100% complete (highly important)
    exposure.route, #water, food, sediment 
    
    ## dose metrics ##
    #dose.um3.mL.master, #volume/volume dose
    #dose.mg.L.master, #mass/volume dose
    #dose.particles.mL.master, #particle/volume dose
    dose.surface.area.um2.mL.master, #area/volume dose
    #dose.specific.surface.area.um2.mg.mL, # specific surface area/volume dose
    
    ## Particle characteristics ##
    polymer, #14 levels
    shape, #4 levels
    size.length.um.used.for.conversions, #continuous, 99.5% complete
    #particle.volume.um3, #continuous, 89% complete
    #density.mg.um.3, #continous, 97% complete
    #particle.surface.area.um2, #continuous surface area
    #particle.surface.area.um2.mg, #specific surface area
    #mass.per.particle.mg, # particle mass
    
    ## Response variable
    effect, # BINARY (y/n) 100% complete
   # effect.metric #Honec, noec, loec, etc. NOTE: NA is an effect, but somewhere along the curve (unassigned magnitude)
                  )) %>% 
  filter(exposure.route == "water") %>% 
  drop_na() %>%  #drop missing
  mutate(effect_10 = case_when( #convert ordinal to numeric
      effect == "Y" ~ 1,
      effect == "N" ~ 0
    )) %>%
  mutate(effect_10 = factor(effect_10)) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::select(-c(effect, 
                   exposure.route#,
                   #effect.metric
                   )) #%>%
  #mutate(sa_vol_ratio = dose.surface.area.um2.mL.master/dose.um3.mL.master)
```

```{r}
response <- as.numeric(as.character(df$effect_10))
predictors <- as.data.frame(df %>% dplyr::select(-effect_10))
#build glm
glm_model <- train(effect_10~., data = df, method = "glm", family = "binomial")
#build explainer for easy interpretation
explainer_glm_model <- DALEX::explain(glm_model, label = "glm", data = predictors, y = response)

#classifier plot
classif_glm2<- model_parts(explainer_glm_model, loss_function = loss_root_mean_square)
#plot classifier
plot(classif_glm2)

final_model <- glm_model
```
### Partial dependence plot
```{r}
p1  <- model_profile(explainer_glm_model, variable = "bio.org", type = "partial")
p2  <- model_profile(explainer_glm_model, variable = "polymer", type = "partial")
p3  <- model_profile(explainer_glm_model, variable = "shape", type = "partial")
p4  <- model_profile(explainer_glm_model, variable = "acute.chronic_f", type = "partial")

plot(p1, p2, p3, p4)
```

Clean up the plot
```{r}
# bio org
org <- p1$agr_profiles %>% 
  as.data.frame()
pp1 <- org %>% 
  rename(bio.org = '_x_',
         tox = '_yhat_') %>%
  ggplot(aes(x = reorder(bio.org, -tox), y = tox)) +
  geom_col(fill = "green") +
  xlab("Biological Level of Organization") +
  ylab("Relative Sensitivity") +
  dark_theme_bw(base_size = 15)

#polymer
pp2 <- p2$agr_profiles %>% 
  as.data.frame() %>% 
  rename(factor = '_x_',
         tox = '_yhat_') %>%
  ggplot(aes(x = reorder(factor, -tox), y = tox)) +
  geom_col(fill = "blue") +
  xlab("Polymer") +
  dark_theme_bw(base_size = 15)

#shape
pp3 <- p3$agr_profiles %>% 
  as.data.frame() %>% 
  rename(factor = '_x_',
         tox = '_yhat_') %>%
  ggplot(aes(x = reorder(factor, -tox), y = tox)) +
  geom_col(fill = "yellow") +
  xlab("Shape") +
  dark_theme_bw(base_size = 15)

#Acute chronic
pp4 <- p4$agr_profiles %>% 
  as.data.frame() %>% 
  rename(factor = '_x_',
         tox = '_yhat_') %>%
  ggplot(aes(x = reorder(factor, -tox), y = tox)) +
  geom_col(fill = "red") +
  xlab("Acute or Chronic") +
  dark_theme_bw(base_size = 15)

grid.arrange(pp1,pp2,pp3,pp4, top = "Relative Toxicity of Variables", bottom = "General Linear Model; Coefficients")
```

```{r}
aoc_z_sub <- aoc_z %>%
  dplyr::select(names(final_model$trainingData)[-1], csf, density.mg.um.3, size.length.um.used.for.conversions)

actual_model_data <- final_model$trainingData %>%
  dplyr::mutate(.outcome = as.numeric(as.character(.outcome))) 
```

# Resources: 
https://pubs.acs.org/doi/suppl/10.1021/acs.est.0c02982/suppl_file/es0c02982_si_001.pdf https://pubs.acs.org/doi/suppl/10.1021/acs.estlett.9b00379/suppl_file/ez9b00379_si_001.pdf
https://pubs.acs.org/doi/10.1021/acs.estlett.9b00379


# Particles constant, volume different
## Generate Particles

Shape is defined as:
Simplifed equation for corey shape factor:

$CSF = H/sqrt(LW)$

Equation for abundance of particles based on density (two distributions). (Note that this is *equation 4* in Kooi and Koelmans (2019).)

The most abundant shape category of microplastic in water and sediment is fibers (48.5%), followed by fragments (31%), beads (6.5%), films (5.5%), and foam (3.5%)(3). Combining these abundance data with the triangular shape distributions (Table S2 and Figure S2) resulted in a continuous bimodal microplastic shape distribution (Figure 2A). The fitted parameter values for eq 4 were as follows: f1 = 0.06, f2 = 0.94, σ1 = 0.03, σ2 = 0.19, μ1 = 0.08, and μ2 = 0.44 (see Table S5 for standard errors). A Pearson χ2 test indicated that the optimized distribution fits the data well (the fitted model did not differ significantly from the data; p = 0.231 > 0.05). The distribution is dominated by fibers and fragments (CSF = 0.25–0.75) but also has a distinct second peak at a CSF of 0.07, which is mainly attributed to sheets (Figure 2A). The distribution captures the main features of shapes encountered in the environment as well as the relative abundances of these (now continuous) shapes in one go. Most illustrative though is the continuous character of microplastic shape.

$y = f1(\frac{1}{sqrt(2pi()\sigma_1^2})e^{-(x-\mu_1)^2/2\sigma_1^2} + f2(\frac{1}{sqrt(2pi()\sigma_2^2})e^{-(x-\mu_2)^2/2\sigma_2^2}$

For polymer abundance, for the K&K2019 paper I used the fixed values from Burns & Boxall review, and went straight for density. Given these fixed relative abundances, you could calculate polymer type randomly for N particles via: 

pols <- c("PE", "PP", "PS")
rel.ab <- c(0.5, 0.3, 0.2)
n = 1000
sample(pols, size = n, prob = rel.ab, replace = TRUE)

Particle volume is determined according to shape as follows:

$V = \frac{\pi}{6}L^3CSF^2$

Where CSF = corey shape factor and L = length.

Particle mass is estimated as follows:

$m = pV*\frac{1}{1e12}*1000$

Where *m* is the mass (mg), *p* is density (g/cm^3), *V* is volume (um^3) - which is calculated by the cube of the length (um) of each particle, and additional conversion factors for mg to g (x1000) and cm^3 to um^3 (1e-12).
```{r, include=FALSE}

#variables to set for funcions
      xmin = 1 #UM
      alpha = 2.07 #for marine surface water Kooi et al 2021
      
      mu1 <- 0.08
      mu2 <- 0.44
      sd1 <- 0.03
      sd2 <- 0.19
      lambda1 <- 0.06
      lambda2 <- 0.94
        
      d.alpha = 73.8 #tail heaviness
      d.beta = 69.9  #asymmetry
      d.mu = 0.840   #location
      d.delta = 0.0972 #scale


X.func <- function (X){
  success <- FALSE
  while (!success){
    U = runif(1, 0, 1)
    X = xmin*(1-U)^(1/(1-alpha))
    success <- X < 5000} ##should be smaller than 5000 um 
  return(X)
}

D.func <- function (D){
  success <- FALSE
  while (!success){
    D = rnig(1, mu = d.mu, alpha = d.alpha, beta = d.beta, delta = d.delta)
    success <- D < 2.63} ## include upper limit of 2.63, the max. 
  return(D)
}


## Create environmentally realistic data
synthetic_data_builder <- function(count, volume_l, addedfactors){
  #Preset parameters for pdfs
   ## Generate values for the three distributions
      set.seed(123)

      Data <- data.frame(Size = numeric(0))
      
      for(i in 1:count){
        X <- X.func()
        Data <- rbind(Data, X)
      }
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## SIZE DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      colnames(Data) <- c("Size")
      
      #min(Data$Size) ##20 um
      #max(Data$Size) ##5000 um
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## SHAPE DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      #Sample N random uniforms U
      U =runif(count)
      
      #Sampling from the mixture
      for(i in 1:count){
        if(U[i]<lambda1){
          Data$Shape[i] = rtnorm(1,mu1,sd1, lower = 0, upper = 1)
        }else{
          Data$Shape[i] = rtnorm(1,mu2,sd2, lower = 0, upper = 1)
        }
      }
      
      min(Data$Shape) ##0
      max(Data$Shape) ##1
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## DENSITY DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      Dens <- data.frame(Density = numeric(0));
      
      for(i in 1:count){
        X <- D.func()
        Dens <- rbind(Dens, X)
      }
      
      colnames(Dens) <- c("Density")
      
      Data <- cbind(Data, Dens)
      
      ##++++++++++++++++++++++++++++++++++++++++
      ## Polymer DISTRIBUTION
      ##++++++++++++++++++++++++++++++++++++++++
      
      pols <- c("PE", "PP", "PS")
      rel.ab <- c(0.5, 0.3, 0.2)
      polymer <- sample(pols, size = count, prob = rel.ab, replace = TRUE)
      Data <- cbind(Data, polymer)
      
      Data %>%  
        mutate(size.category = factor(case_when(
          Size < 10 & Size >= 1 ~ "1µm < 10µm",
          Size < 100 & Size >= 10 ~ "10µm < 100µm",
          Size < 1000 & Size >= 100 ~ "100µm < 1mm",
          Size < 5000 & Size >= 1000 ~ "1mm < 5mm"))) %>% 
        mutate(mass.mg = Density * Size^3 * 1E-9) %>% 
        mutate(um3 = (Size^3)) %>%
        bind_cols(addedfactors[rep(1, times = nrow(.)),]) %>% 
        mutate(vol.L = volume_l) %>% 
        mutate(vol.mL = vol.L * 1000) %>% 
        mutate(dose.um3.mL.master = um3 / vol.mL) %>% 
        mutate(dose.particles.mL.master = 1 / vol.mL) %>% 
        mutate(dose.mg.L.master = mass.mg / vol.L) %>% 
        mutate(particles.total = factor(as.character(count)))
}

add_prediction <- function(fun, model, ...){
        fun(...) %>%
        mutate_if(~is.numeric(.) && (.) > 0, log10) %>%
        bind_cols(predict(model, newdata = ., type = "prob") %>% 
        rename("ToxicityProbability" = `1`))                  
}

```


Test synthetic data.

```{r}
possible_variables <- aoc_z_sub %>%
        # dplyr::select(treatments,
        #        organism.group,
        #        exposure.duration.d,
        #        lvl1_f,
        #        life.stage,
        #        bio.org,
        #        effect.metric,
        #        environment,
        #        exposure.route,
        #        lvl2_f) %>%
        distinct()

##++++++++++++++++++++++++++++++++++++++++
## Quick check results
##++++++++++++++++++++++++++++++++++++++++
skim(synthetic_data_builder(count = 10000, 
                                    volume_l = 1000, 
                                    addedfactors = possible_variables[488,]
                                    ))
```


### Uniform Distribution

It may be possible to visualize discrete relationships of toxicity by creating a uniform distribution of particles within the parameter space of the training dataset, then plotting the predicted toxicities for different predictors.

#### Generate uniform particles
```{r}
n = 1000
<<<<<<< HEAD
>>>>>>> 508e2335b27f94933f95cad8551f8a1b93876383
#Create uniform characteristics for base particle characteristics (size, shape, density)v
=======
#Create uniform characteristics for base particle characteristics (size, shape, density)
>>>>>>> c7e146dcd0aef3fbb3aea0915b66e7c0e0c77d42
csf <- runif(n, min = min(aoc_z$csf, na.rm = T), max(aoc_z$csf, na.rm = T)) #Set this to parameter space 
#mass.per.particle.mg <- runif(n, min = 0, max = 1.65e+1)
density.mg.um.3 <- runif(n, min = min(aoc_z$density.mg.um.3, na.rm = T), max = max(aoc_z$density.mg.um.3, na.rm = T))
size.length.um.used.for.conversions <- runif(n, min = min(aoc_z$size.length.um.used.for.conversions, na.rm = T), max = max(aoc_z$size.length.um.used.for.conversions, na.rm = T))

#create uniform distribution of polymer types
#pols <- c("PE", "PP", "PS", "PVC", "PET")
#rel.ab <- c(0.2, 0.2, 0.2, 0.2, 0.2)
#polymer <- sample(pols, size = n, prob = rel.ab, replace = TRUE)

#surface area equation for elongated spheres (fragments)
SAfnx = function(a, # length
                 b, # width
                 c){ # height
  SA = 4*pi*(((a*b)^1.6 + (a*c)^1.6 + (b*c)^1.6) / 3)^(1/1.6)
  return(SA)}

#Volume equation for elongated sphere (fragments)
volumefnx = function(R, L){
  volume = 0.111667 * pi * R^2 * L^3 #assumes height = 0.67 * Width, and Width:Length ratio is 'R' (0.77 average in marine surface water)
  return(volume)}

#create data frame with uniform distirbutions
unif_df <- data.frame(csf, density.mg.um.3, size.length.um.used.for.conversions) %>%
  mutate(mass.per.particle.mg = density.mg.um.3 * size.length.um.used.for.conversions ^ 3 * 1E-9) %>% 
  mutate(particle.volume.um3 = pi/6 * (size.length.um.used.for.conversions ^ 3) * csf ^2 ) %>% #equation 4
  #volume
  mutate(vol.mL = 0.0001) %>% 
  mutate(vol.L = vol.mL / 1000) %>%  
  mutate(dose.um3.mL.master = particle.volume.um3 / vol.mL) %>% 
  mutate(dose.particles.mL.master = 1 / vol.mL) %>% 
  mutate(dose.mg.L.master = mass.per.particle.mg / vol.L) %>% 
  #calculate surface area based on shape
  mutate(particle.surface.area.um2 = SAfnx(a = size.length.um.used.for.conversions,
                                           b = 0.77 * size.length.um.used.for.conversions,
                                           c = 0.77 * 0.67 * size.length.um.used.for.conversions)) %>% 
  mutate(dose.surface.area.um2.mL.master = particle.surface.area.um2 * dose.particles.mL.master)
  
  

skim(unif_df)
```
HIGHLIGHT AREA UNDER THE CURVE
If we go down to lower number, we would not adequately mimic distribution. Stick to creating 1E5 particles, then change volume. 
Could capture variability for small bumbers by simulating small number of particles


How to calculate uncertainties? 
  Replace effect parameters by median +- SD, then predict tox for each distribution, plot, then if it is minor, FORGET about it! REsiduals in Merel's models were not randomly distributed -  so imperfect models.
  
What sizes should be used?
  1-5,000 um. 

Wait for Merel to update interactions between shape/size/density/count.
  
What about max size ingest?
  Tox studies typically do not exposure animals to particles bigger than their mouth size opening, so model may not understand that relationship. 
  Could impose bioavailable fraction AFTER model. JUST do predictions for species that have bioavailable fraction data. Could estimate mouth size from prey to predator fraction. JAMS et al has mouth-size opening parameters.

Non-linear regression to get dose-response. 

Mattson, Hasselof, Frontiers in Science - measures size distribution. 

Final figure: SINGLE toxicity prediction for each dose. Use environmental data. Make SSD. Risk Characterization. The model's SSD is fundamentally different from the SSD made from monodisperse particles, so it is MORE reliable. 
Big assumption: all particle toxicities are ADDITIVE! Depends on effect mechanism - food dilution. 


# Dose-response curves
Part of me just wants to set the uniform distribution to the distinct version of the dataset. That way we can define uncertainty for each dose response curve and are not extrapolating within ranges (sometimes people just get data for the max and min in a distribution that doesn't mean that we know what the middle should be.)

```{r}
#creates new datatable that has all organism endpoint information in it
org_endpoint_comb <- aoc_z %>%
  dplyr::select(organism.group, 
                bio.org, 
                lvl2_f,
                max.size.ingest.mm,
                acute.chronic_f,
                exposure.route,
                species_f) %>%
  distinct() 

# expands using uniform dataframe
df_expand <- org_endpoint_comb %>%
  expand_grid(unif_df)

#Ran the code below too to see if the glm methods were the same. They are returning the same response. 
df_expand$prob <- predict.glm(final_model, df_expand, type = "response")

for(row in 1:nrow(org_endpoint_comb)){
  slice <- org_endpoint_comb[row,]
  doses <- inner_join(df_expand, slice) %>%
    dplyr::select(-organism.group, -bio.org, -lvl1_f) %>%
    pivot_longer(cols = -prob, names_to = "type", values_to = "values")
 plot <- ggplot(doses) + geom_point(aes(x = values, y = prob)) + facet_wrap(type~., scales = "free") + labs(title = paste0(as.character(unlist(slice)), collapse = "_"))
  ggsave(plot = plot, filename = paste0(paste0(as.character(unlist(slice)), collapse = "_"), ".png"), path = "Tox Data/figures")
}  



#Testing this out for actual data, not extrapolated uniform data using the training dataset.
org_endpoint_comb <- actual_model_data %>%
  dplyr::select_if(function(col) is.character(col) | 
                                   is.factor(col)) %>%
  distinct() 

df_expand <- actual_model_data 

for(row in 1:nrow(org_endpoint_comb)){
  slice <- org_endpoint_comb[row,]
  doses <- inner_join(df_expand, slice) %>%
    dplyr::select_if(is.numeric) %>%
    pivot_longer(cols = -.outcome, names_to = "type", values_to = "values")
 plot <- ggplot(doses) + geom_point(aes(x = values, y = .outcome)) + facet_wrap(type~., scales = "free") + labs(title = paste0(as.character(unlist(slice)), collapse = "_"))
  ggsave(plot = plot, filename = paste0(paste0(as.character(unlist(slice)), collapse = "_"), ".png"), path = "Tox Data/figures")
}  



```

# SSD

```{r}



df_expand_sensitivity_distribution <- df_expand %>%
  filter(prob > 0.5) %>%
  group_by(organism.group, bio.org, lvl1_f) %>% #Can add other factors here if we want to flesh this out for each organism.
  summarise(dose.um3.mL.master = min(dose.um3.mL.master), dose.surface.area.um2.mL.master = min(dose.surface.area.um2.mL.master)) %>%
  ungroup()

ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.surface.area.um2.mL.master))

ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.um3.mL.master))

#Other Option with automated extraction from the dataset. 

df_expand_sensitivity_distribution <- df_expand %>%
  filter(.outcome > 0.5) %>%
  group_by_if(function(col) is.character(col) | 
                                   is.factor(col)) %>% #Can add other factors here if we want to flesh this out for each organism.
  summarise_if(is.numeric, min) %>%
  ungroup()

ggplot(df_expand_sensitivity_distribution) + stat_ecdf(aes(x = dose.particles.mL.master))


```

#Run Merels distribution through the model to predict the liklihood of risk in the environment for organism endpoint combinations. 




# Sensitivity Analysis
it would be great to use the full approach to find out which model parameters and MP subclasses the HC5 is most sensitive to.And also if that HC5 is sensitive to which of Merel’s compartment-specific MP parameterisations is used.

# Shiny App Tabs
1) ML predictor
2) Chemical data
  Bioaccumulation model, partitioning with chemicals/particles. Would add toxicity from chemicals to toxicity from particles! Use same model from Worm paper. Would show how it would compare with toxicities from particles. We have criticial body burden concept (lipids) 
