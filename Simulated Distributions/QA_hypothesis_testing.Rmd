---
title: "QA as Predictor for Effects"
author: "Scott Coffin"
date: "02/3/2022"
output:   
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
    includes:
     # after_body: footer.html
  word_document:
    toc: yes
---


#Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=8, fig.path='Figs2/',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

## Libraries
```{r library}
# Bimodal universal shape distribution for environmental microplastic from Kooi and Koelmans (2019)
library(truncnorm)
library(tidyverse)
library(MonteCarlo)# Monte Carlo Simulation 
library(gridExtra)
library(msm) ## rtnorm - get upper and lower limit of shape distribution
library(GeneralizedHyperbolic) ## normal-inverse Gaussian
library(skimr)
library(drc) #dose-response curves
library(readr)
library(readxl)
library(DALEX)
library(tigerstats)
library(caret)
library(knitr)
library(modelplotr)
library(rsample)
library(interpret) #explainable boosting machine
library(ssdtools)
library(ggrepel)
library(scales)
library(ggdark)
library(ggsci)
library(ggpubr)
library(randomForest)
```

## Themes
```{r Theme, include=FALSE}
#Theme type
     theme.type<- theme_bw(base_size = 14) +
                  #     dark_theme_bw(base_size = 15) +
                    theme(plot.title = element_text(hjust = 0.5),
                    plot.subtitle = element_text(hjust = 0.5))

     #color selection
     fill.type <-    #scale_fill_viridis(discrete = TRUE)#,
                         #scale_fill_brewer(palette = "Paired"),
                         # scale_fill_tron()#,
                         # scale_fill_locuszoom(),
                         # scale_fill_d3(),
                          scale_fill_npg()#,
                         # scale_fill_jama())
     #color selection
     color.type <- #scale_color_viridis(discrete = TRUE)#,
                         # scale_color_brewer(palette = "Paired"),
                          #scale_color_tron()#,
                         # scale_color_locuszoom(),
                         # scale_color_d3(),
                          scale_color_npg()#,
                         # scale_color_jama())

```
## Data Import
```{r data import}
require(readr)
#load aoc_z into dataframe. This file is generated from RDA_Maker.R
#source("Tox Data/RDA_Maker.R")
aoc_z <- readRDS(file = "Tox Data/aoc_z.Rda") 
## Data filtering
```
## Data filtering

To ensure quality data feeds the model, we are filtering for technical red criteria.
```{r}
## First filter data with global filters
aoc_intermediate <- aoc_z %>% 
 # filter(size.length.um.used.for.conversions > 1) %>%  #alignments only valid above 1 um
  #filter(
    #tier_zero_tech_f == "Red Criteria Passed",  ################# MAKE SURE TO UNCOMMENT THIS WHEN RUNNING REAL MODEL!!!!!! ######
     #    tier_zero_risk_f == "Red Criteria Passed", ################# MAKE SURE TO UNCOMMENT THIS WHEN RUNNING REAL MODEL!!!!!! ######
        # polymer != "Not Reported",
  #       !environment %in% c("Terrestrial", "Not Reported"),
   #      org_f != "Bacterium",
    #     org_f != "Plant",
         #effect.metric != "HONEC"
     #    ) %>% 
  #Remove 26C temperature treatment data from Jaimukar et al. 2018
  #filter(!(article == 42 & media.temp == 26)) %>% 
  mutate(max.size.ingest.um = 1000 * max.size.ingest.mm) %>%   #makes it less confusing below
  #filter(risk.13 != 0) %>%  #Drop studies that received a score of 0 for endpoints criteria (this also drops studies that have not yet been scored) - KEEP THIS AFTER THE RED CRITERIA FILTERS  )
  droplevels()  #eliminate polymer aand shape data that's not needed
```


## Data Alignment to ERMs
#### Parameters
```{r}
## parametrization ##
# Define params for correction #
alpha = 2.07 #table s4 for marine surface water. length
# define parameters for power law coefficients
a.sa = 1.5 #marine surface area power law
a.v = 1.48 #a_V for marine surface water volume
a.m = 1.32 # upper limit fora_m for mass for marine surface water in table S4 
a.ssa = 1.98 # A_SSA for marine surface water

#define additional parameters for calculations based on averages in the environment
R.ave = 0.77 #average width to length ratio for microplastics in marine enviornment
p.ave = 1.10 #average density in marine surface water

#join alpha values for each data point
aoc_intermediate_alphas <- aoc_intermediate %>% 
  mutate(alpha = alpha) %>% 
  mutate(a.sa = a.sa) %>% 
   mutate(a.v =  a.v) %>% 
   mutate(a.m =  a.m) %>% 
   mutate(a.ssa = a.ssa) %>% 
   mutate(R.ave = R.ave) %>% 
   mutate(p.ave = p.ave)
```

#### Functions
```{r}
###function to derive correction factor (CF) from Koelmans et al (equation 2)
CFfnx = function(a, #default alpha from Koelmans et al (2020)
                 x2D, #set detault values to convert ranges to (1-5,000 um) #5mm is upper defuault 
                 x1D, #1 um is lower default size
                 x2M, x1M){
  CF = (x2D^(1-a)-x1D^(1-a))/(x2M^(1-a)-x1M^(1-a)) 
  return(CF)}

#### equations for mu_x_poly (note that there are three depending on certain alphas for limits of equation)
#generalizable if a.x =2 or not
mux.polyfnx_generalizable = Vectorize(function(a.x, x_UL, x_LL){
  if(a.x == 1){ # in case a.x = 1
    mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL))
    return(mux.poly)}
  if(a.x == 2){ # in case a.x = 2
     mux.poly = (log10(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
     return(mux.poly)}
  else{ #in case alpha is not 2 or 1
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}
  },
  vectorize.args = "a.x") # if Vectorize isn't here, the if else won't work
## ^^ Note that the above generalizable function doesn't play well with mutate(case_when), likely due to some bug with dplyr. I don't have a solution to this, so a special equation will need to be used when those values are used...

#in case alpha is not 1 or 2
mux.polyfnx = function(a.x, x_UL, x_LL){
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}

##### If alpha does equal 2 #####
mux.polyfnx2 = function(a.x, x_UL,x_LL){
  mux.poly = (log(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
  return(mux.poly)}

##### If alpha equals 1 #####
mux.polyfnx1 = function(a.x, x_UL, x_LL){
     mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL)) #natural log
    return(mux.poly)}

### Calculating max ingestible parameters ###
## function to calcualte min and max ingestible surface area ##
SAfnx = function(a, # a = 0.5 * length
                 b, # b = 0.5 * width
                 c # c = 0.5 * height (note that hieght is 0.67 * width)
){
  SA = 4*pi*(((a*b)^1.6 + (a*c)^1.6 + (b*c)^1.6) / 3)^(1/1.6)
  return(SA)}

## max ingestible volume ##

volumefnx = function(R, L){
  volume = 0.111667 * pi * R^2 * L^3 #assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
  return(volume)}

volumefnx_poly = function(width, length){
  height = 0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  return(volume)}

#max ingestible mass (only used for mu_mono calculations)
massfnx = function(R, L, p){
  mass = p * #density (g/cm^3)
    0.111667 * pi * R^2 * L^3 * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

massfnx_poly = function(width, length, p){
  height = 0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  mass = p * #density (g/cm^3)
    volume * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

#max ingestible specific surface area
SSAfnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA = sa/m
    return(SSA)}

#max ingestible specific surface area
SSA.inversefnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA.inverse = m / sa
    return(SSA.inverse)}
```

#### Calculate

Here we will calculate two aligned exposure concentrations: surface area (1 - 83 um), and volume (1 - 5,000 um). For both, the upper aligned value is the smaller of either the nominal size listed or the mouth size of the species.

```{r}
###define sizes for alignment##
x1M_set <- 1 #um lower size for all alignments
x1D_set <- 1 #um lower size for all alignments
x2D_set <- 5000 #um
upper.tissue.trans.size.um <- 83 #10 #um #set size for x2M

# calculate ERM for each species
aoc_final <- aoc_intermediate_alphas  %>% 
   #### TISSUE TRANSLOCATION ####
# define upper size length for Translocation 
#set to 83um for upper limit or max size ingest, whichever is smaller
mutate(x2M_trans = case_when(is.na(max.size.ingest.um) ~ upper.tissue.trans.size.um, 
                             max.size.ingest.um  < upper.tissue.trans.size.um ~  max.size.ingest.um,
                             max.size.ingest.um  > upper.tissue.trans.size.um ~ upper.tissue.trans.size.um)) %>% 
  
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_trans = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_trans = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_trans, #upper ingestible size limit (width of particle)
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.p.mono)/mu.p.poly_trans) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_trans = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_trans, #upper translocatable
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_trans = EC_poly_p.particles.mL_trans * CF_bio_trans) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  #### Surface area ERM ####
##--- environmental calculations ---###
  #calculate lower translocatable surface area
  mutate(x_LL_sa_trans = SAfnx(a = 0.5 * x1D_set, #length
                               b = 0.5 * x1D_set, #0.5 * R.ave * x1D_set, #width
                               c = 0.5 * x1D_set  #0.5 * R.ave * 0.67 * x1D_set #height
                               )) %>%  
  #calculate upper translocatable surface area
  mutate(x_UL_sa_trans = SAfnx(a = 0.5 * x2M_trans, 
                               b = 0.5 * x2M_trans, #width #0.5 * R.ave * x2M, 
                               c = 0.5 * x2M_trans #heigth #0.5 * R.ave * 0.67 * x2M
                               )) %>%  
  #calculate mu_x_poly (env) for surface area
  mutate(mu.sa.poly_trans = mux.polyfnx(a.sa, x_UL_sa_trans, x_LL_sa_trans)) %>% 
  
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.sa.mono = case_when(
    polydispersity == "monodisperse" ~ particle.surface.area.um2, # use reported surface area in monodisperse
    polydispersity == "polydisperse" ~  mux.polyfnx(a.x = a.sa, 
                                  x_LL = particle.surface.area.um2.min,
                                  x_UL = particle.surface.area.um2.max))) %>% 
  
   #calculate polydisperse effect concentration for surface area (particles/mL)
  mutate(EC_poly_sa.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.sa.mono)/mu.sa.poly_trans) %>%  
  #calculate environmentally realistic effect threshold
  mutate(EC_env_sa.particles.mL_trans = EC_poly_sa.particles.mL_trans * CF_bio_trans) %>% 
  
  ##### FOOD DILUTION ####
  # define upper size length for ingestion 
  mutate(x2M_ingest = case_when(is.na(max.size.ingest.um) ~ x2D_set, 
                         max.size.ingest.um < x2D_set ~ max.size.ingest.um,
                         max.size.ingest.um > x2D_set ~ x2D_set
                         )) %>%  #set to 5,000 as upper limit or max size ingest, whichever is smaller
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_ingest = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_ingest = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_ingest, #upper ingestible size limit
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.p.mono)/mu.p.poly_ingest) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_ingest = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_ingest, #upper ingestible length
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default upper size range
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_ingest = EC_poly_p.particles.mL_ingest * CF_bio_ingest) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  
  #### volume ERM ####
##--- environmental calculations ---###
  #calculate lower ingestible volume 
  mutate(x_LL_v_ingest = volumefnx_poly(length = x1D_set,
                                 width = x1D_set)) %>% 
  #calculate maximum ingestible volume 
  mutate(x_UL_v_ingest = volumefnx_poly(length = x2M_ingest, # length-limited
                                 #x2D_set, #upper definiton (accouunts for fibers) CONSERVATIVE
                                 width = x2M_ingest)) %>% #ingestion-limited
  # calculate mu.v.poly
  mutate(mu.v.poly_ingest = mux.polyfnx(a.v, x_UL_v_ingest, x_LL_v_ingest)) %>% 
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.v.mono = case_when(
    polydispersity == "monodisperse" ~ particle.volume.um3, # use reported volume in monodisperse
    polydispersity == "polydisperse" ~ mux.polyfnx(a.x = a.v, 
                                                   x_LL = particle.volume.um3.min,
                                                   x_UL = particle.volume.um3.max))) %>% 
  
  #calculate polydisperse effect concentration for volume (particles/mL)
  mutate(EC_poly_v.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.v.mono)/mu.v.poly_ingest) %>%  
    #calculate environmentally realistic effect threshold
  mutate(EC_env_v.particles.mL_ingest = EC_poly_v.particles.mL_ingest * CF_bio_ingest) %>% 
  
   ###### CLEANUP #####
  mutate(particles.mL.ox.stress = EC_env_sa.particles.mL_trans,
         particles.mL.food.dilution = EC_env_v.particles.mL_ingest)
```

#Study Quality Over Time
```{r}
my.formula <- y ~ x

# long data
long_time <- aoc_final %>% 
  dplyr::select(c(year, risk.quality, technical.quality#, total.quality
                  )) %>% 
  mutate(year_date = lubridate::ymd(year, truncated = 2L)) %>% 
  pivot_longer(cols = -c(year_date, year), names_to = "quality_type", values_to = "score")

#scatterplot
scatterplot <- long_time %>% 
  ggplot(aes(x = year_date, y = score, color = quality_type, fill = quality_type)) +
  geom_point(position=position_jitterdodge(), alpha = 0.03) +
   geom_smooth(method = "lm", se=TRUE, formula = my.formula) +
   ggpmisc::stat_poly_eq(formula = my.formula, 
                aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., sep = "~~~")), 
                parse = TRUE) +         
 # geom_rug(position=position_jitterdodge(), alpha = 0.5) +
  scale_x_date(labels = date_format("%Y"),
               date_breaks = "1 year",
               limits = as.Date(c("2012-01-01", "2020-07-01"))) +
  scale_color_aaas(labels = c("Risk Quality Score", "Technical Quality Score")) +
  scale_fill_aaas(labels = c("Risk Quality Score", "Technical Quality Score")) +
  theme.type +
  theme(legend.position=c(0.63,0.98),legend.justification=c(1,1),
        axis.title.x = element_blank(),
        legend.title = element_blank()) 

#marginal density plot of x - plot on bnottom
plot_bottom <- long_time %>%
  ggplot(aes(x = year_date)) +
  geom_bar() +
  #geom_density() +
  scale_x_date(labels = date_format("%Y"),
               date_breaks = "1 year",
               limits = as.Date(c("2012-01-01", "2020-7-1"))) +
  ylab("Study Frequency") +
  theme.type +
  theme(axis.title.x = element_blank(),
        axis.text.y = element_blank())

quality_time <- grid.arrange(scatterplot,
             #empty, 
             plot_bottom,
             ncol = 1, nrow = 2, 
             #widths = c(1,1),
             heights = c(4,1))

ggsave(plot = quality_time,
       filename = "quality_time.jpeg",
       path = "output/figures/", 
       width = 10, height = 8, units = "in",
       bg = "white",
       dpi = 300)

quality_time
```


# Does Study Quality Predict Likelihood of finding an effect?
## Data subsetting
Bart asked this question
```{r}
# data preparation
QA <- aoc_final %>% 
  #filter(poly_f != "Not Reported") %>% 
 #filter data select predictor variables#
  dplyr::select(c(
                 #-rowid,
    ### Quality Metrics ###
                  technical.quality,
                  risk.quality,
                  total.quality,
                  risk.tier.zero,
                  tech.tier.zero,
    ### DOSE METRICS ####
                  #particles.mL.ox.stress,
                  particles.mL.food.dilution,
                  #dose.mg.L.master, 
                  #dose.surface.area.um2.mL.master, #fibers are assumed to be cylinders, fragments are assumed to be spheres
                  #dose.particles.mL.master, 
                  organism.group, 
                  life.stage, #use adults for prediction
                  species_f, 
                  max.size.ingest.mm,
    ### Exposure Conditions ####              
                  bio.org, #use tissue and above for lower tiers, organism and above for higher tiers
                  exposure.route, #train on all, but only use "aquatic" for build
                  environment, #train on all, buit only use "marine" for SSD Build
                  acute.chronic_f, #use 'chronic' for SSD build
                  exposure.duration.d, 
    ### Particle characteristics ####
                  polymer, 
                  shape,
                  #density.g.cm3,
                  #size.length.um.used.for.conversions, #we can't use size because we're using mixtures of particles! Have to specify translocatable or not
                  translocatable,
    ### Effect data ####
                 # effect, 
                  effect.score, #relative numerical strength of effect
                  effect.metric, #train on all, but only specify "NOEC" for SSD build
                  lvl1_f, #keep it generic for easy SSD build (use fitness)
                  lvl2_f
                  )) %>% 
  mutate(log10.particles.mL.food.dilution = log10(particles.mL.food.dilution)) %>%  
  dplyr::select(-particles.mL.food.dilution) %>% 
  mutate(effect.metric = (case_when(
    effect.metric == "NOEC" ~ "NOEC",
    effect.metric == "NONEC" ~ "NOEC",
    effect.metric == "HONEC" ~ "NOEC",
    effect.metric == "LOEC" ~ "LOEC",
    effect.metric == "LC50" ~ "LC50",
    effect.metric == "EC50" ~"EC50",
    effect.metric == "EC10" ~ "EC10"
  ))) %>% 
 mutate(effect.metric = as.character(effect.metric)) %>% 
   mutate(effect.metric = replace_na(effect.metric,"not_available")) %>% 
  mutate(effect.metric = as.factor(effect.metric)) %>% 
  mutate_if(is.character, as.factor) %>% 
   dplyr::rename(c("Species" = species_f, 
                       "Organism Group" = organism.group,
                       "Environment" = environment,
                       "Life Stage" = life.stage,
            "Estimated Maximum Ingestible Size (mm)" = max.size.ingest.mm,
            "Exposure Route" = exposure.route,
            "Exposure Duration (days)" = exposure.duration.d,
            "Acute/Chronic" = acute.chronic_f,
            "Broad Endpoint Category" = lvl1_f, 
            "Specific Endpoint Category" = lvl2_f,
            "Level of Biological Organization" = bio.org, 
             "Effect Metric" = effect.metric,
            "Effect Score" = effect.score,
             "Empirical Food Dilution ERM Conc. (log 10 particles/mL; 1-5,000 um)" = log10.particles.mL.food.dilution)) %>% 
  drop_na()

```

## Data split
```{r}
# Create a training data set with the training() function
# Pulls from training and testing sets created by initial_split()
split_QA <- QA %>%
  initial_split(prop = 0.75)
QA_test <- testing(split_QA)
QA_train <- training(split_QA)


yTest <- as.numeric(as.character(QA_test$`Empirical Food Dilution ERM Conc. (log 10 particles/mL; 1-5,000 um)`))

test_x <- as.data.frame(QA_test %>% dplyr::select(- `Empirical Food Dilution ERM Conc. (log 10 particles/mL; 1-5,000 um)`))

```

## ML Model 
```{r}
QA_rf <- train(`Empirical Food Dilution ERM Conc. (log 10 particles/mL; 1-5,000 um)` ~ ., 
                  data = QA_train, method = "rf", ntree = 100, tuneLength = 1)

explainer_rf_QA <- DALEX::explain(QA_rf,
                                       label = "rf",
                                       data = QA_test, 
                                       y = yTest)

explainer_rf_QA$model$results
```

### Variable Importance
```{r}
variable_importance_rf_QA <- model_parts(explainer_rf_QA, loss_function = loss_root_mean_square)

plot(variable_importance_rf_QA)
```

### Partial Dependence Plot
```{r}
pdp_classif_rf  <- model_profile(explainer_rf_QA, variable = "technical.quality")

plot(pdp_classif_rf)
```
```{r}
pdp_classif_rf_risk  <- model_profile(explainer_rf_QA, variable = "risk.quality")

plot(pdp_classif_rf_risk)
```

# Binomial with effect/no-effect
## Random Forest
```{r}
QA_binomial <- aoc_final %>% 
  mutate_if(is.character, as.factor) %>%
#choose relevant predictors and log-transform
  dplyr::select(
                #response  
                effect_f, 
                #quality params
                technical.quality,
                  risk.quality,
                  total.quality,
                  risk.tier.zero,
                  tech.tier.zero,
                #other params
                size.length.um.used.for.conversions,
                shape,
                polymer,
                particle.volume.um3,
                density.mg.um.3, 
                organism.group, 
                bio.org, 
                exposure.duration.d, 
                exposure.route, 
                lvl1_f, 
                dose.mg.L.master) %>% 
    drop_na() %>%  #drop missing
  filter(risk.quality > 0) %>% 
  mutate_if(~is.numeric(.) && (.) > 0, log10)
 # mutate(effect_10 = case_when( #convert ordinal to numeric
 #     effect_f == "Yes" ~ 1,
 #     effect_f == "No" ~ 0)) %>% 
 #  dplyr::select(- effect_f)

skim(QA_binomial)
```

## Data split
```{r}
# Create a training data set with the training() function
# Pulls from training and testing sets created by initial_split()
split_QA_binomial <- QA_binomial %>%
  initial_split(prop = 0.75)
QA_binomial_test <- testing(split_QA_binomial)
QA_binomial_train <- training(split_QA_binomial)
```

## ML Model 
```{r}
# Random forest -- 
set.seed(2) # assures the data pulled is random, but sets it for the run below (makes outcome stable)

QA_binomial_rf <- randomForest(y = QA_binomial_train$effect_f, # dependent variable
  x = QA_binomial_train %>%
    dplyr::select(-effect_f), # selecting nofilter predictor variables
  importance = T, # how useful is a predictor in predicting values (nothing causal)
  proximity = T, 
  ntrees = 100) # 500 trees default. 

QA_binomial_rf # examine the results.
```

```{r}
plot(QA_binomial_rf)
# model performance appears to improve most at ~75 trees
```

```{r}
varImpPlot(QA_binomial_rf)
# displays which variables are most important; helps to winnow down list of predictors; recommended to weigh left pane more; right pane also shows how evenly things split based on the list of predictors; values close to 0 can be dropped, but don't have to be
```


```{r}
require(pROC)
predicted <- predict(QA_binomial_rf, QA_binomial_test %>%  dplyr::select(-effect_f),
                       OOB=TRUE, type= "response")
#Calculate ROC curve
rocCurve.tree <- roc(as.numeric(QA_binomial_test$effect_f),as.numeric(predicted))

##gplot
# rocks <- roc()

#plot the ROC curve
plot(rocCurve.tree,col=c(4))
```

### Variable Importance
```{r}
explainer_classif_rf_QA_binomial <- DALEX::explain(QA_binomial_rf,
                                       label = "rf",
                                       data = QA_binomial_test, 
                                       y = QA_binomial_test$effect_f)

explainer_classif_rf_QA_binomial$model

variable_importance_rf_QA_binomial <- model_parts(explainer_classif_rf_QA_binomial, loss_function = loss_root_mean_square)

plot(variable_importance_rf_QA_binomial)
```

### Partial Dependence Plot
```{r}
pdp_classif_rf  <- model_profile(explainer_classif_rf_QA_binomial, variable = "technical.quality")

plot(pdp_classif_rf)
```
```{r}
pdp_classif_rf_risk  <- model_profile(explainer_classif_rf_QA_binomial, variable = "risk.quality")

plot(pdp_classif_rf_risk)
```

# Stepwise Multiple Regression
## GLM
### Build full model
```{r}
QA_step <- QA_binomial %>% 
  mutate(effect_10 = case_when( #convert ordinal to numeric
      effect_f == "Yes" ~ 1,
      effect_f == "No" ~ 0)) %>% 
   dplyr::select(- effect_f)

Full_Model <- glm(effect_10 ~., data = QA_step)

summary(Full_Model)
```
### Stepwise Regression
```{r}
#Stepwise model
step.model <- stepAIC(Full_Model, direction = "both", 
                      trace = FALSE)


summary(step.model)

```

## Linear Model
```{r}
Linear_Model <- lm(effect_10 ~., data = QA_step)

summary(Linear_Model)
```


### Stepwise Regression
```{r}
#Stepwise model
step.model.linear <- stepAIC(Linear_Model, direction = "both", 
                      trace = FALSE)

summary(step.model.linear)
```

## Visualization
```{r}
tech <- QA_step %>% 
  ggplot(aes(x = technical.quality, y = effect_10)) +
 # geom_point() +
  geom_smooth(family = "glm") +
  theme.type

risk <- QA_step %>% 
  ggplot(aes(x = risk.quality, y = effect_10)) +
  #geom_point() +
  geom_smooth() +
  theme.type

dose <- QA_step %>% 
  ggplot(aes(x = dose.mg.L.master, y = effect_10)) +
 # geom_jitter() +
  geom_smooth() +
  theme.type

size <- QA_step %>% 
  ggplot(aes(x = size.length.um.used.for.conversions, y = effect_10)) +
 # geom_jitter() +
  geom_smooth() +
  theme.type

grid.arrange(tech, risk, dose, size)
```
# Chi-Square Test
```{r}
chi <- aoc_final %>% 
  dplyr::select(c(
    ### Quality Metrics ###
                 # technical.quality,
                  #risk.quality,
                  #total.quality,
                  risk.tier.zero,
                  tech.tier.zero,
                  effect_f))
```
## Risk Tier (binary) vs. Effect (binary)
### Likelihood
```{r}
#risk tier zero
chisq.risk <- chisq.test(chi$effect_f, chi$risk.tier.zero)

chisq.risk
```

### Contingency Table
```{r}
kable(table(chi$effect_f, chi$risk.tier.zero),
      caption = "Risk Tier (Pass/Fail) vs. Effect (Yes, No)")
```
### Contingency Heatmap
```{r}
chi %>% 
  drop_na() %>% 
  group_by(effect_f, risk.tier.zero) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = effect_f, y = risk.tier.zero, fill = count)) +
  geom_tile() +
  geom_text(aes(label = round(count, 1))) +
    scale_fill_gradient(low = "white", high = "red")+
  labs(title = "Risk Quality (Pass/Fail) vs. Effect (Yes/No)",
       subtitle = paste("Chi-Square p =", round(chisq.risk$p.value,3))) +
  theme.type +
  theme(legend.position = "none")

```

## Tech Tier (binary) vs. Effect (binary)
### Likelihood
```{r}
#tech tier zero
chisq.tech <- chisq.test(chi$effect_f, chi$tech.tier.zero)
chisq.tech
```

### Contingency Table
```{r}
kable(table(chi$effect_f, chi$tech.tier.zero),
      caption = "Technical Quality Tier (Pass/Fail) vs. Effect (Yes, No)")
```

### Contingency Heatmap
```{r}
chi %>% 
  drop_na() %>% 
  group_by(effect_f, tech.tier.zero) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = effect_f, y = tech.tier.zero, fill = count)) +
  geom_tile() +
  geom_text(aes(label = round(count, 1))) +
    scale_fill_gradient(low = "white", high = "red")+
  labs(title = "Technical Quality (Pass/Fail) vs. Effect (Yes/No)",
       subtitle = paste("Chi-Square p =", round(chisq.tech$p.value,5))) +
  theme.type +
  theme(legend.position = "none")

```

